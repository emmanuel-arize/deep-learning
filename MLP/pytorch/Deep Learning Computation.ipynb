{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Custom-Layers\" data-toc-modified-id=\"Custom-Layers-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Custom Layers</a></span></li><li><span><a href=\"#The-Sequential-Block\" data-toc-modified-id=\"The-Sequential-Block-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>The Sequential Block</a></span></li><li><span><a href=\"#Parameter-Management\" data-toc-modified-id=\"Parameter-Management-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Parameter Management</a></span></li><li><span><a href=\"#Parameter-Access\" data-toc-modified-id=\"Parameter-Access-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Parameter Access</a></span></li><li><span><a href=\"#All-Parameters-at-Once\" data-toc-modified-id=\"All-Parameters-at-Once-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>All Parameters at Once</a></span></li><li><span><a href=\"#Parameter-Initialization\" data-toc-modified-id=\"Parameter-Initialization-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Parameter Initialization</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.weight1=nn.Parameter(torch.rand(3,5))\n",
    "        self.bias1=nn.Parameter(torch.randn(5,))\n",
    "        self.weight2=nn.Parameter(torch.randn(5,1))\n",
    "        self.bias2=nn.Parameter(torch.randn(1,))\n",
    "    def forward(self,inputs):\n",
    "        h1=F.relu(torch.matmul(inputs,self.weight1.data)+self.bias1.data)\n",
    "        output=torch.matmul(h1,self.weight2.data)+self.bias2.data\n",
    "        return output\n",
    "net=MLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1754, 0.6151, 0.7223],\n",
       "        [0.0396, 0.1980, 0.6702],\n",
       "        [0.8456, 0.9100, 0.4330],\n",
       "        [0.7901, 0.0625, 0.4999],\n",
       "        [0.5814, 0.6105, 0.0684],\n",
       "        [0.9576, 0.4503, 0.9600],\n",
       "        [0.7145, 0.7802, 0.1436],\n",
       "        [0.1509, 0.2680, 0.8937],\n",
       "        [0.4680, 0.0214, 0.7032],\n",
       "        [0.2488, 0.5711, 0.0697]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#torch.randn-Returns a tensor filled with random numbers from a normal distribution\n",
    "#x=torch.Tensor(10,3).normal_(0,1)\n",
    "#x=torch.Tensor(10,3).uniform_(0,1)\n",
    "# torch.rand-Returns a tensor filled with random numbers from a uniform distribution\n",
    "x=torch.rand(10,3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-4.1595],\n",
       "        [-3.6810],\n",
       "        [-4.2358],\n",
       "        [-3.5359],\n",
       "        [-3.6290],\n",
       "        [-4.2945],\n",
       "        [-3.8576],\n",
       "        [-3.9727],\n",
       "        [-3.6241],\n",
       "        [-3.5629]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lr1=nn.Linear(3,5)\n",
    "        self.relu=nn.ReLU()\n",
    "        self.lr2=nn.Linear(5,1)\n",
    "        #  initializing the parameters\n",
    "        self.lr1.weight.detach().normal_(0.0,0.1)\n",
    "        self.lr1.bias.detach().zero_()\n",
    "        self.lr2.weight.detach().normal_(0.0,0.1)\n",
    "        self.lr2.bias.detach().zero_()\n",
    "\n",
    "    def forward(self,inputs):\n",
    "        h1=self.relu(self.lr1(inputs))\n",
    "        output=self.lr2(h1)\n",
    "        return output\n",
    "net=MLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0029],\n",
       "        [-0.0105],\n",
       "        [-0.0012],\n",
       "        [-0.0153],\n",
       "        [-0.0004],\n",
       "        [-0.0140],\n",
       "        [-0.0006],\n",
       "        [-0.0142],\n",
       "        [-0.0222],\n",
       "        [-0.0003]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Sequential Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySequential(nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super().__init__()\n",
    "        for block in args:\n",
    "            self._modules[block]=block\n",
    "    def forward(self,x):\n",
    "        for block in self._modules.values():\n",
    "            x=block(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "net=MySequential(\n",
    "                   nn.Linear(3,5),\n",
    "                    nn.ReLU(), \n",
    "                    nn.Linear(5,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.rand(10,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0129],\n",
       "        [ 0.0784],\n",
       "        [ 0.0917],\n",
       "        [ 0.0117],\n",
       "        [-0.0061],\n",
       "        [-0.0427],\n",
       "        [ 0.0132],\n",
       "        [ 0.0742],\n",
       "        [ 0.0908],\n",
       "        [ 0.0695]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "net=nn.Sequential(\n",
    "                   nn.Linear(3,5),\n",
    "                    nn.ReLU(), \n",
    "                    nn.Linear(5,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1962],\n",
       "        [0.2450],\n",
       "        [0.1304],\n",
       "        [0.2098],\n",
       "        [0.1785],\n",
       "        [0.2105],\n",
       "        [0.2206],\n",
       "        [0.1488],\n",
       "        [0.2406],\n",
       "        [0.1012]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = nn.Sequential(\n",
    " nn.Linear(3,4),nn.ReLU(),nn.Linear(4,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5037,  0.3265],\n",
       "        [-0.3941,  0.1183],\n",
       "        [-0.4305,  0.2336],\n",
       "        [-0.3946,  0.1286],\n",
       "        [-0.3957,  0.1567],\n",
       "        [-0.5187,  0.3427],\n",
       "        [-0.4630,  0.2665],\n",
       "        [-0.4431,  0.2495],\n",
       "        [-0.4036,  0.1581],\n",
       "        [-0.4731,  0.3077]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.2014,  0.2191, -0.3463, -0.4553]) \n",
      "\n",
      "Parameter containing:\n",
      "tensor([-0.2014,  0.2191, -0.3463, -0.4553], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(network[0].bias.data,'\\n')\n",
    "print(network[0].bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1901, -0.0140, -0.3808, -0.4765],\n",
      "        [ 0.2652,  0.3377,  0.4329, -0.0679]]) \n",
      "\n",
      "Parameter containing:\n",
      "tensor([[-0.1901, -0.0140, -0.3808, -0.4765],\n",
      "        [ 0.2652,  0.3377,  0.4329, -0.0679]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(network[2].weight.data,'\\n')\n",
    "print(network[2].weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Parameters at Once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight', tensor([[ 0.5381, -0.4474, -0.4941],\n",
       "                      [-0.1267,  0.1290,  0.3772],\n",
       "                      [-0.2581,  0.4610,  0.5257],\n",
       "                      [ 0.4608, -0.5509, -0.0230]])),\n",
       "             ('0.bias', tensor([-0.2014,  0.2191, -0.3463, -0.4553])),\n",
       "             ('2.weight', tensor([[-0.1901, -0.0140, -0.3808, -0.4765],\n",
       "                      [ 0.2652,  0.3377,  0.4329, -0.0679]])),\n",
       "             ('2.bias', tensor([-0.3904,  0.0274]))])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.named_modules of Sequential(\n",
       "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=4, out_features=2, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.named_modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP1(nn.Module):\n",
    "    def __init__(self,**kwargs):\n",
    "        super().__init__()\n",
    "        self.lr1=nn.Linear(3,5)\n",
    "        self.relu=nn.ReLU()\n",
    "        self.lr2=nn.Linear(5,1)\n",
    "    def forward(self,inputs):\n",
    "        h1=self.relu(self.lr1(x))\n",
    "        return self.lr2(h1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "nett=MLP1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2565],\n",
       "        [0.1754],\n",
       "        [0.3915],\n",
       "        [0.2705],\n",
       "        [0.3569],\n",
       "        [0.2121],\n",
       "        [0.2735],\n",
       "        [0.3721],\n",
       "        [0.1774],\n",
       "        [0.4157]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nett(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0887, -0.3614,  0.3325],\n",
       "        [-0.1560,  0.3222, -0.4743],\n",
       "        [ 0.3742,  0.4434, -0.0769],\n",
       "        [-0.0317,  0.0601, -0.0036],\n",
       "        [-0.2493,  0.2729,  0.0655]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nett.lr1.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0887, -0.3614,  0.3325],\n",
       "        [-0.1560,  0.3222, -0.4743],\n",
       "        [ 0.3742,  0.4434, -0.0769],\n",
       "        [-0.0317,  0.0601, -0.0036],\n",
       "        [-0.2493,  0.2729,  0.0655]], requires_grad=True)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nett.lr1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4157])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nett.lr2.bias.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of MLP1(\n",
       "  (lr1): Linear(in_features=3, out_features=5, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (lr2): Linear(in_features=5, out_features=1, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nett.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('lr1.weight', tensor([[-0.0887, -0.3614,  0.3325],\n",
       "                      [-0.1560,  0.3222, -0.4743],\n",
       "                      [ 0.3742,  0.4434, -0.0769],\n",
       "                      [-0.0317,  0.0601, -0.0036],\n",
       "                      [-0.2493,  0.2729,  0.0655]])),\n",
       "             ('lr1.bias',\n",
       "              tensor([-0.4845,  0.3708, -0.1654, -0.4358, -0.3950])),\n",
       "             ('lr2.weight',\n",
       "              tensor([[-0.2624, -0.4453, -0.1863,  0.3561, -0.3224]])),\n",
       "             ('lr2.bias', tensor([0.4157]))])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nett.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Parameter Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "nett.lr1.weight.data=torch.empty(size=(5,3)).normal_(mean=0,std=0.01)\n",
    "nett.lr1.bias.data=torch.empty(size=(5,)).normal_(mean=0,std=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('lr1.weight', tensor([[-0.0049,  0.0184,  0.0062],\n",
       "                      [ 0.0100, -0.0077, -0.0080],\n",
       "                      [ 0.0057, -0.0088,  0.0058],\n",
       "                      [ 0.0027, -0.0103,  0.0018],\n",
       "                      [ 0.0097, -0.0044,  0.0090]])),\n",
       "             ('lr1.bias',\n",
       "              tensor([-0.0042, -0.0093, -0.0074, -0.0087, -0.0168])),\n",
       "             ('lr2.weight',\n",
       "              tensor([[-0.2624, -0.4453, -0.1863,  0.3561, -0.3224]])),\n",
       "             ('lr2.bias', tensor([0.4157]))])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nett.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=3, out_features=4, bias=True)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def xavier(m):\n",
    "    if type(m)==nn.Linear:\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        \n",
    "network[0].apply(xavier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this post, I will explain the internal mechanisms that allow GRU’s to perform so\n",
    "well when  model temporal sequences and their long-range dependencies more accurately \n",
    "than the coventional RNNs then use it in real life problem by training GRU as a multi-class \n",
    "classifier to predict the tag of a programming question on Stack Overflow using Keras.\n",
    "\n",
    "> Note: In order to understand this post, you must have basic knowledge of recurrent neural networks and Keras. You can refer to the <a href='https://emmanuel-arize.github.io/datascience-blog/deeplearning/deep-learning/2021/05/06/RNN.html' target=\"_blank\">  recurrent neural network</a> to understand these concepts:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a coventional <a href='https://emmanuel-arize.github.io/datascience-blog/deeplearning/deep-learning/2021/05/06/RNN.html' target=\"_blank\">  recurrent neural network</a>, during the backpropagation phase, in which the error signal (gradients) are backpropagated through time, the recurrent hidden layers (weight matrix associated with the layers) are subject to repeated multiplications as determined by as the number of timesteps (length of the sequence), and this might result in numerical instability for lengthy sequence. For lengthy sequence, small weights tends to lead to a situation known as <b>vanishing gradients</b> \n",
    "where the error signal propagating backwards gets so small that learning either becomes very slow or stops working altogether (error signals fowing backwards in time tend to vanish). <b>Conversely </b>larger weights tends to lead to a situation where the error signal is so large that it can cause learning to diverge , a situation known as <b>exploding gradients</b>.\n",
    "\n",
    "To read more on exploding and vanishing gradients have a look at this papers\n",
    "<br/>\n",
    "<a href='https://arxiv.org/pdf/1211.5063v1.pdf' target=\"_blank\">Understanding the exploding gradient problem</a><br/>\n",
    "<a href='https://www.semanticscholar.org/paper/Learning-long-term-dependencies-with-gradient-is-Bengio-Simard/d0be39ee052d246ae99c082a565aba25b811be2d' target=\"_blank\">Learning long-term dependencies with gradient descent is difficult</a><br/> \n",
    "\n",
    "<a href='https://www.bioinf.jku.at/publications/older/2304.pdf' target=\"_blank\">THE VANISHING GRADIENT PROBLEM DURING LEARNING RECURRENT NEURAL NETS AND PROBLEM SOLUTIONS</a><br/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The vanishing and exploding gradients problem, limit the ability of conventional RNNs in modeling sequences with long range contextual dependencies and to address these issues, more complex network architectures known as Gated Neural Networks (GNNs) have been designed to help mitigate this problem by introducing ***“gates”***  to control the flow of information into and out of the  network layers. There are several GNNs but in this post we will learn about a notable example  known as <a href='https://arxiv.org/pdf/1406.1078v3.pdf' target='_blank'>Gated Recurrent Unit or GRU (Cho et al., 2014)</a>) which is similar to LSTM but with fewer parameters than LSTM, as it lacks an output gate and faster to train due to the simpler architecture. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Architecture of Gated Recurrent Units (GRU)\n",
    "\n",
    "\n",
    "<img img id='lstm'  class=\"w3-center\" src=\"{{'/assets/images/deep/keras/GRU.png' |relative_url}}\"><span id='Fig'>Figure 1</span>\n",
    "<a href='https://www.researchgate.net/figure/Structure-of-the-LSTM-cell-and-equations-that-describe-the-gates-of-an-LSTM-cell_fig5_329362532'>source <a/>\n",
    "\n",
    "<img id='GRU' src=\"./images/GRU.png\" /><span id='GRU'>Figure 1</span>\n",
    "<a href='https://en.wikipedia.org/wiki/File:Gated_Recurrent_Unit,_base_type.svg'>Source</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From <a href='#GRU'>Figure 1</a> ***GRU has two gates, a reset $(r_{t})$ and update gates $(z_{t})$ ***. Tthe reset gate determines how to combine the new input with the previous hidden state. let assume we have a minibatch of inputs $X_{t} \\in R^{n×d}$ where each row of $X_{t}$ corresponds to one example at time step ***t*** from the sequence and the hidden state of the previous time step as $h_{t−1} \\in R^{n×h}$. Given an input, the first step of the GRU model is for the reset gate to decide whether to ignore the previous hidden state or not. With a reset gate value close to 0, the previous hidden state is dimmed irrelevant and the hidden state is forced to ignore the previous hidden state and reset with the current input. The reset gate is defined as\n",
    "\n",
    "\n",
    "$$ r_{t}=\\sigma(W_{xr}X_{t}+U_{hr}h_{t-1}+b_{r} )$$\n",
    "\n",
    "where $W_{xr}$, $U_{hr}$ are weight paramaters, $b_r$ the bias term and $\\sigma$ is the sigmoid activation function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ***update gate*** is defined as\n",
    "\n",
    "$$ z_{t}=\\sigma(W_{xz}X_{t}+U_{hz}h_{t-1}+b_{z})$$\n",
    "\n",
    "and it controls how information from the previous hidden state are carried over to the current hidden state\n",
    "\n",
    "Let now examine how the reset and update gates are integrated into the hidden state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>The Hidden State</b> is computed by\n",
    "$$ h_{t}=z_{t} \\odot h_{t-1}+ (1-z_{t})\\odot \\bar h_{t} $$\n",
    "\n",
    "where\n",
    "\n",
    "$$\\bar h_{t}=\\phi(W_{h}X_{t}+U_{h}(r_{t} \\odot h_{t-1})+b_{z})$$\n",
    "\n",
    "is known as the ***Candidate Hidden State*** , the operator $\\odot$ denotes the Hadamard product and the update gate **$z_t$** decides whether the hidden state is to be updated with\n",
    "the new Candidate Hidden State $\\bar h$  . \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ z_{t}=\\sigma(W_{xz}X_{t}+U_{hz}h_{t-1}+b_{z} \\rightarrow update \\ gate \\ vector$$\n",
    "\n",
    "\n",
    "$$ r_{t}=\\sigma(W_{xr}X_{t}+U_{hr}h_{t-1}+b_{r} \\rightarrow reset \\ gate \\ vector $$\n",
    "\n",
    "\n",
    "\n",
    "$$\\bar h_{t}=\\phi(W_{h}X_{t}+U_{h}(r_{t} \\odot h_{t-1})+b_{z}) \\rightarrow candidate\\ hidden\\ state$$\n",
    "\n",
    "\n",
    "$$ h_{t}=z_{t} \\odot h_{t-1}+ (1-z_{t})\\odot \\bar h_{t} \\rightarrow hidden \\ state $$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multi-class classification on Stack Overflow questions\n",
    "This tutorial showed how to train a multi-class classifier to predict the tag of a programming question on Stack Overflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import string\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as K\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import preprocessing\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment to download the data\n",
    "# url='http://storage.googleapis.com/download.tensorflow.org/data/stack_overflow_16k.tar.gz'\n",
    "# dataset=tf.keras.utils.get_file('stack_overflow',origin=url,untar=True,cache_dir='./data',\n",
    "#                                 cache_subdir='stackoverflow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dir(data):\n",
    "    dataset_dir=os.path.join(os.path.dirname('.'),data)\n",
    "    stackoverflow=os.path.join(os.path.dirname(dataset_dir),'stackoverflow/')\n",
    "    train_dir=os.path.join(os.path.dirname(stackoverflow),'train')\n",
    "    test_dir=os.path.join(os.path.dirname(stackoverflow),'test')\n",
    "    return train_dir, test_dir    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir,test_dir=load_dir('data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['csharp', 'java', 'javascript', 'python'],\n",
       " ['csharp', 'java', 'javascript', 'python'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(train_dir),os.listdir(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 files belonging to 4 classes.\n",
      "Using 6800 files for training.\n",
      "Found 8000 files belonging to 4 classes.\n",
      "Using 1200 files for validation.\n",
      "Found 8000 files belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size=10\n",
    "train_data=preprocessing.text_dataset_from_directory(directory=train_dir,subset='training',\n",
    "                                                    validation_split=0.15,batch_size=batch_size,\n",
    "                                                    seed=20)\n",
    "val_data=preprocessing.text_dataset_from_directory(directory=train_dir,subset='validation',\n",
    "                                                    validation_split=0.15,seed=20\n",
    "                                                     )\n",
    "test_data=preprocessing.text_dataset_from_directory(directory=test_dir,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 0  for the label corresponds to  csharp\n",
      "index 1  for the label corresponds to  java\n",
      "index 2  for the label corresponds to  javascript\n",
      "index 3  for the label corresponds to  python\n"
     ]
    }
   ],
   "source": [
    "for i,label in enumerate(train_data.class_names):\n",
    "    print('index' ,i,\" for the label corresponds to \", label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\"blank clean up of (local) objects referenced in \"\"delayed\"\" functions does blank (pure, not jquery, if it matters) know to clear up/free/release from the last reference to an object in a \"\"delayed\"\" function called from a timer or event?..take the following code:..function myinitfunc().{.  var myinitobj = new object();.  myinitobj.properties = lotsofstuff;..  var mydelayedinitfunc = function ().  {.    dosomethingwith(myinitobj);.    // i shall not be accessing myinitobj again now..  };..  // let\\'s say, *one* of the following:.  settimeout(mydelayedinitfunc, 1000);.  window.addeventlistener(\\'load\\', mydelayedinitfunc);.  document.addeventlistener(\\'domcontentloaded\\', mydelayedinitfunc);.}...note that mydelayedinitfunc() is deliberately accessing variable myinitobj, which is local to myinitfunc()...in, say, http://blank.info/tutorial/memory-leaks it states \"\"functions used in settimeout/setinterval are also referenced internally and tracked until complete, then cleaned up\"\".  does this \"\"clean up\"\" understand that it can get rid of the myinitobj as well as the function itself?  i\\'m sort of guessing it does......what about the two event examples?  even though we know they are \"\"one-shot\"\" events, i\\'m guessing that neither mydelayedinitfunc nor myinitobj will get cleaned up?..if it is the case that some of these do not clean up, should i make mydelayedfunc() set myinitobj = null; at its end so as to minimise the wastage?\"\\n'\n",
      " \n",
      " \n",
      "\n",
      "csharp\n",
      " \n",
      " \n",
      " \n",
      "b\"how to load config file in blank from an external module i have a config module (myconfig.py) present in a library for which i created a standard distribution package using setuptools...  --configpackage.    |.    | ---- myconfig.py.    | ---- __init__.py...myconfig.py is a key value pair like this:..my_name = 'myname'.my_age = '99'...now i have another blank project where i import this config module like this   ..import configpackage.myconfig as customconfig...if this config file was native to my blank project and had not come from an external project then i would have done something like this:..app = flask(__name__) .app.config.from_object('app.configpackage.config')...where config is actually config.py file under configpackage. ..and any key value pair in config.py could then be accessed as .. myname = app.config['my_name']...my problem is that i am not able to load the external config file in the above mentioned way for a native config file. what i have tried is this which doesn't work:..import configpackage.myconfig as customconfig..app = flask(__name__) .app.config.from_object(customconfig).myname = app.config['my_name']...i get the following error..model_name =  app.config['model_name'].keyerror: 'model_name'..which means that it is not able to load the config file from external module correctly. can anyone tell me the right way to accomplish this ?\\n\"\n",
      " \n",
      " \n",
      "\n",
      "csharp\n",
      " \n",
      " \n",
      " \n",
      "b'\"saving currency textbox values in blank i had this class for currency textbox which i downloaded...the code works fine when i enter values in the currency textbox. but when i try to execute my insert query from a stored procedure, this error appears:...  error converting data type nvarchar to decimal....i don\\'t where the error is...this is the code for the class currency textbox;..using system;.using system.linq;.using system.windows.forms;.using system.globalization;..namespace ssfasys.{.    public partial class currencytextbox:textbox.    {.        readonly cultureinfo _ci = cultureinfo.installeduiculture;.        private readonly string _allowedcharacterset;.        private readonly char _decimalseparator;..        public currencytextbox().        {.            var nf = new cultureinfo(_ci.name, false).numberformat;.            _decimalseparator = nf.currencydecimalseparator.tochararray()[0];.            _allowedcharacterset = string.format(\"\"0123456789{0}\"\", _decimalseparator);..            initializecomponent();.        }.        /// return currency text with no formatting.        public string textnoformatting.        {.            get { return typedtext(); }.        }..        protected override void onleave(eventargs e).        {.            decimal amount;.            text = decimal.tryparse(text, numberstyles.currency, null, .            out amount) ? amount.tostring(\"\"n\"\") : 0.tostring(\"\"n\"\");.            base.onleave(e);.        }..        private string typedtext().        {.            var sonuc = string.empty;.            return text.trim().where(ch =&gt; _allowedcharacterset.contains(ch)).aggregate.            (sonuc, (current, ch) =&gt; current + ch);.        }..        protected override void onenter(eventargs e).        {     .            text = typedtext();.            base.onenter(e);.        }..        protected override void onkeypress(keypresseventargs e).        {.            if (!char.isdigit(e.keychar) &amp;&amp; .            e.keychar != _decimalseparator &amp;&amp; !char.iscontrol(e.keychar)).            {.                e.handled = true;.            }.            base.onkeypress(e);.        }..        private void initializecomponent().        {.            this.suspendlayout();.            // .            // currencytextbox.            // .            this.font = new system.drawing.font(\"\"consolas\"\", 12f, system.drawing.fontstyle.regular, system.drawing.graphicsunit.point, ((byte)(0)));.            this.resumelayout(false);..        }.    }.}...and this is my stored procedure for inserting the value of the currency textbox;..private void scholarshipinputs().        {.            if (cmbclass.text == string.empty).            {.                messagebox.show(\"\"please fill-in required classification of scholarship to proceed.\"\");..            else if (currencytextboxamount.text == string.empty).            {.                messagebox.show(\"\"please indicate a specific amount granted for this scholarship program to proceed.\"\");.            }.            else if (cmbclass.text == string.empty &amp;&amp; cmbtype.text == string.empty &amp;&amp; cmbcode.text == string.empty &amp;&amp; cmbdesc.text == string.empty &amp;&amp; cmbterm.text == string.empty &amp;&amp; currencytextboxamount.text == string.empty).            {.                messagebox.show(\"\"please fill-in all required fields to proceed.\"\");.            }.            else.            {.                sqlcon.open();.                sqlcommand cmd = new sqlcommand();.                cmd.commandtext = \"\"insertssfapsdetails\"\";.                cmd.commandtype = commandtype.storedprocedure;.                cmd.connection = sqlcon;.                cmd.parameters.add(new sqlparameter(\"\"@ssfaptype\"\", ssfaptype));.                cmd.parameters.add(new sqlparameter(\"\"@ssfapsclass\"\", ssfapclass));.                cmd.parameters.add(new sqlparameter(\"\"@amount\"\", currencytextboxamount.text));.                cmd.parameters.add(new sqlparameter(\"\"@ssfapscode\"\", cmbcode.text));.                cmd.parameters.add(new sqlparameter(\"\"@ssfapsdesc\"\", cmbdesc.text));.                cmd.parameters.add(new sqlparameter(\"\"@term\"\", cmbterm.text));.                int rowsaffected = cmd.executenonquery();.                if (rowsaffected &gt; 0).                {.                    messagebox.show(\"\"scholarship program successfully included for the term.\"\");.                    cmbclass.refresh();.                    cmbtype.refresh();.                    cmbcode.text = \"\"\"\";.                    cmbdesc.text = \"\"\"\";.                    cmbterm.text = \"\"\"\";.                    currencytextboxamount.text = \"\"\"\";.                }.                else .                {.                    messagebox.show(\"\"no scholarship program included for the term. please contact your system administrator to fix the problem.\"\");.                }.                sqlcon.close();.            }.        }\"\\n'\n",
      " \n",
      " \n",
      "\n",
      "csharp\n",
      " \n",
      " \n",
      " \n"
     ]
    }
   ],
   "source": [
    "for x,y in train_data.take(3):\n",
    "    for i in range(1):\n",
    "        X=(x.numpy()[i])\n",
    "        print(x.numpy()[i])\n",
    "        print(' \\n \\n')\n",
    "        print(train_data.class_names[i])\n",
    "        print(' \\n \\n ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first time the dataset is iterated over, its elements will be cached\n",
    "either in the specified file or in memory. Subsequent iterations will\n",
    "use the cached data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=train_data.cache().prefetch(tf.data.AUTOTUNE)\n",
    "val_data=val_data.cache().prefetch(tf.data.AUTOTUNE)\n",
    "test_data=test_data.cache().prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_br(input_data):\n",
    "    lowercase = tf.strings.lower(input_data)\n",
    "    lowercase=tf.strings.strip(lowercase)    \n",
    "    stripped_html = tf.strings.regex_replace(lowercase,\"<[^>]+>\" , '')\n",
    "    return tf.strings.regex_replace(stripped_html,\n",
    "                                  '[%s]' % re.escape(string.punctuation), '')\n",
    "max_features = 10000  # Maximum vocab size.\n",
    "max_tokens=200\n",
    "\n",
    "encode_input=TextVectorization(standardize=remove_br,\n",
    "                               max_tokens=max_features,output_mode='int',\n",
    "                               output_sequence_length=max_tokens\n",
    "                                )\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_input.adapt(train_data.map(lambda x,y:x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_dim=16\n",
    "class GRU(K.models.Model):\n",
    "    def __init__(self):\n",
    "        super(GRU,self).__init__()\n",
    "        self.embedd=K.layers.Embedding(input_dim=max_features,output_dim=embedded_dim,\n",
    "                                       input_length=max_tokens)\n",
    "        self.gru=K.layers.GRU(32)\n",
    "        self.f=K.layers.Flatten()\n",
    "        self.dense=K.layers.Dense(4,activation='softmax')\n",
    "        self.drop=K.layers.Dropout(0.3)\n",
    "    def call(self,x):\n",
    "        encoder=encode_input(x)\n",
    "        embedd=self.embedd(encoder)\n",
    "        gru=self.gru(embedd)\n",
    "        f=self.f(gru)\n",
    "        drop=self.drop(f)\n",
    "        output=self.dense(drop)\n",
    "        return output\n",
    "gru=GRU()\n",
    "# since the labels for each class are integers we will use  'sparse_categorical_crossentropy'\n",
    "# as the loss function\n",
    "gru.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "680/680 [==============================] - 80s 115ms/step - loss: 1.3860 - acc: 0.2508 - val_loss: 1.3751 - val_acc: 0.2783\n",
      "Epoch 2/20\n",
      "680/680 [==============================] - 86s 127ms/step - loss: 1.3464 - acc: 0.2998 - val_loss: 1.2138 - val_acc: 0.3833\n",
      "Epoch 3/20\n",
      "680/680 [==============================] - 70s 103ms/step - loss: 1.2090 - acc: 0.3844 - val_loss: 1.1921 - val_acc: 0.3908\n",
      "Epoch 4/20\n",
      "680/680 [==============================] - 67s 98ms/step - loss: 1.1968 - acc: 0.4030 - val_loss: 1.2219 - val_acc: 0.3775loss: 1.1974 - ac - ETA: 2s - \n",
      "Epoch 5/20\n",
      "680/680 [==============================] - 70s 104ms/step - loss: 1.1739 - acc: 0.4166 - val_loss: 1.1560 - val_acc: 0.4033\n",
      "Epoch 6/20\n",
      "680/680 [==============================] - 74s 109ms/step - loss: 1.1618 - acc: 0.4281 - val_loss: 1.1395 - val_acc: 0.4233\n",
      "Epoch 7/20\n",
      "680/680 [==============================] - 72s 106ms/step - loss: 1.1319 - acc: 0.4498 - val_loss: 1.1314 - val_acc: 0.4258 1s - loss: 1.\n",
      "Epoch 8/20\n",
      "680/680 [==============================] - 72s 106ms/step - loss: 1.1197 - acc: 0.4707 - val_loss: 1.1067 - val_acc: 0.4517\n",
      "Epoch 9/20\n",
      "680/680 [==============================] - 76s 111ms/step - loss: 1.0966 - acc: 0.4745 - val_loss: 1.1194 - val_acc: 0.4500\n",
      "Epoch 10/20\n",
      "680/680 [==============================] - 66s 97ms/step - loss: 1.0707 - acc: 0.5006 - val_loss: 1.0982 - val_acc: 0.4592\n",
      "Epoch 11/20\n",
      "680/680 [==============================] - 67s 98ms/step - loss: 1.0360 - acc: 0.5250 - val_loss: 1.0682 - val_acc: 0.4883\n",
      "Epoch 12/20\n",
      "680/680 [==============================] - 65s 96ms/step - loss: 0.9968 - acc: 0.5361 - val_loss: 1.0385 - val_acc: 0.4933\n",
      "Epoch 13/20\n",
      "680/680 [==============================] - 67s 99ms/step - loss: 0.9856 - acc: 0.5457 - val_loss: 1.0219 - val_acc: 0.4958\n",
      "Epoch 14/20\n",
      "680/680 [==============================] - 66s 97ms/step - loss: 0.9592 - acc: 0.5488 - val_loss: 1.0006 - val_acc: 0.5167\n",
      "Epoch 15/20\n",
      "680/680 [==============================] - 64s 95ms/step - loss: 0.9406 - acc: 0.5518 - val_loss: 1.0174 - val_acc: 0.5117\n",
      "Epoch 16/20\n",
      "680/680 [==============================] - 63s 92ms/step - loss: 0.9232 - acc: 0.5632 - val_loss: 1.0020 - val_acc: 0.5267\n",
      "Epoch 17/20\n",
      "680/680 [==============================] - 65s 95ms/step - loss: 0.9176 - acc: 0.5701 - val_loss: 0.9610 - val_acc: 0.5250\n",
      "Epoch 18/20\n",
      "680/680 [==============================] - 74s 108ms/step - loss: 0.8932 - acc: 0.5848 - val_loss: 0.9574 - val_acc: 0.5467\n",
      "Epoch 19/20\n",
      "680/680 [==============================] - 76s 112ms/step - loss: 0.8769 - acc: 0.5923 - val_loss: 0.8792 - val_acc: 0.6242\n",
      "Epoch 20/20\n",
      "680/680 [==============================] - 70s 102ms/step - loss: 0.7887 - acc: 0.6613 - val_loss: 0.9588 - val_acc: 0.6600\n"
     ]
    }
   ],
   "source": [
    "history=gru.fit(train_data,batch_size=batch_size,epochs=20,validation_data=val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 24s 30ms/step - loss: 0.9667 - acc: 0.6501\n"
     ]
    }
   ],
   "source": [
    "loss,acc=gru.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Let use the model to predict the sample below from the test set.\n",
    "\n",
    "according the text data the label for the samples are as follows:\n",
    "\n",
    "\n",
    "|-------------|--------------|\n",
    "| sample      |  Labels      |\n",
    "|-------------|--------------|\n",
    "| sample 1    |  python      |\n",
    "|-------------|--------------|\n",
    "| sample 2    |  javascript  |\n",
    "|-------------|--------------|\n",
    "| sample 3    |  java        |\n",
    "|-------------|--------------|\n",
    "| sample 4    |  python      |\n",
    "|-------------|--------------|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample=[\"variables keep changing back to their original value inside a while loop i am doing the mitx 6.00.01x course and i am on the second problem set on the 3rd problem and i am stuck. .my code:  ..    balance = 320000.    annualinterestrate = 0.2.    monthlyinterestrate = (annualinterestrate) / 12.0.    monthlyfixedpayment = 0.    empbalance = balance.    lowerbound = round((balance)/12,2).    upperbound = (balance*(1+monthlyinterestrate)**12)/12.    monthlyfixedpayment = round( ( (lowerbound+upperbound)/2) ,2).    while tempbalance != 0: .        monthlyfixedpayment = round( ( (lowerbound+upperbound)/2) ,2)  .        for m in range(12) :.            tempbalance -= monthlyfixedpayment .            tempbalance += (monthlyinterestrate)*(tempbalance).            tempbalance = round(tempbalance,2) .        if tempbalance &gt; 0:.            lowerbound = round(monthlyfixedpayment,2).            tempbalance = balance.        elif tempbalance &lt; 0: .            upperbound = round(monthlyfixedpayment,2).            tempbalance = balance..    print('lowest payment: ' + str(round(monthlyfixedpayment,2)))...my code uses bisection search to generate the monthlyfixedpayment but after i get to the lines at the end that changes the upperbound or lowerbound values and then start the loop again, the lowerbound and upperbound values reset to their values to the ones outside the loop. does anyone knows how to prevent this?\",\n",
    "        \"how pass window handler from one page to another? (blank) i have a very strange problem , please donâ€™t ask me why do i need thisâ€¦.i have a page1. page1 has a link which opens new window (page2) using  window.open function..chatwindow is a handler of child window with returns from window.open function..now i'm moving from page1 to page3 (by link &lt;a href=\"\"....\"\" target=\"\"_self\"\"&gt;some text&lt;/a&gt;). and i need to check on the page3 if page2 is close or open..how to pass handler chatwindow from page1 to page3?..thank you in advance!\",\n",
    "        \"what is the difference between text and string? in going through the blankfx tutorial i've run into the text, and it's being used where i would have thought a string would be used. is the only difference between..string foo = new string(\"\"bat\"\");...and..text bar = new text(\"\"bat\"\");...that bar cannot be edited, or are there other differences that i haven't been able to find in my research?\",\n",
    "        \"idiomatic blank iterating and adding to a dict i'm running through a string, creating all substrings of size 10, and adding them to a dict. this is my code,..sequence_map = {}.for i in range(len(s)):.    sub = s[i:i+10].    if sub in sequence_map:.       sequence_map[sub] += 1.    else:.       sequence_map[sub] = 1...is there a way to do this more blankically?..also how do i do the reverse blankically, as in interating through the dict and composing a list where value is equal to something?..[k for k, v in sequence_map.items()]\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred(result):\n",
    "    for i in result:\n",
    "        if i==0:\n",
    "            print('csharp')\n",
    "        elif i==1:\n",
    "            print('java')\n",
    "        elif i==2:\n",
    "            print('javascript')\n",
    "        elif i==3:\n",
    "            print('python')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result=tf.argmax(gru.predict(sample)).numpy()\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "javascript\n",
      "javascript\n",
      "csharp\n",
      "java\n"
     ]
    }
   ],
   "source": [
    "pred(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> <b>References:</b></p>\n",
    "<a href='https://arxiv.org/pdf/1406.1078v3.pdf' target='_blank'>Gated Recurrent Unit or GRU (Cho et al., 2014)</a>\n",
    "\n",
    "<a href='https://d2l.ai/chapter_recurrent-modern/gru.html' target='_blank'\n",
    "title=\"Dive Into Deep Learning Chapter 9\">Gated Recurrent Units (GRU)</a>\n",
    "\n",
    "<a href='https://en.wikipedia.org/wiki/Gated_recurrent_unit' target='_blank'\n",
    "title=\"wikipedia\">Gated Recurrent Units</a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

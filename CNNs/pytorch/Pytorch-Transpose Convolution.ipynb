{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0860c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import skimage.data as sc_data\n",
    "import sympy as sy\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['image.cmap']='gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64ad369",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1000)\n",
    "np.random.seed(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b579eef6",
   "metadata": {},
   "source": [
    "# Convolutional Layer\n",
    "\n",
    "\n",
    "A convolutional layer consist of a set of learnable kernels (filters). During the forward pass, we cross-correlate (slide) each kernel across the width and height of the input `I` and compute dot products between the entries of the kernel and the input at any position. As we slide the filter or kernel over the width and height of the input we will produce a 2-dimensional feature map that gives the responses of that filter at every spatial position. \n",
    "\n",
    "\n",
    "An input `I` of size $I_{h} × I_{w}$ and a kernel `K` of size $K_{h} × K_{w}$ sliding with a size $S_{h} × S_{w}$  \n",
    "will give an  `Output` of size\n",
    "$output=\\frac{I_{}-K_{h}+S_{h}}{S_{h}} \\times \\frac{I_{w}-K_{w}+S_{w}}{S_{w}} $\n",
    "\n",
    " If we represent the size of output by $m \\times n$ where $m =\\frac{I_{}-K_{h}+S_{h}}{S_{h}}$ and $n= \\frac{I_{w}-K_{w}+S_{w}}{S_{w}} $\n",
    "\n",
    "The output size is given by the  $floor(m) \\times floor(n)   $\n",
    "\n",
    "The output size is given by the  $\\lfloor{m}\\rfloor \\times \\lfloor{n}\\rfloor $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22281d7",
   "metadata": {},
   "source": [
    " # Transpose Convolution\n",
    "\n",
    "Transposed convolution upsample the spatial dimensions of the intermediate feature maps (inputs) which are reduced by the convolution  operations.\n",
    "\n",
    "# NOTE:\n",
    ">   Transposed convolutions – also called `fractionally strided convolutions or deconvolutions` – work by swapping the forward and backward passes of a convolution. One way to put it is to note that the kernel defines a convolution, but whether it’s a direct convolution or a transposed convolution is determined by how the forward and backward passes are computed.\n",
    "([A guide to convolution arithmetic for deep learning, 2018](https://arxiv.org/abs/1603.07285))\n",
    "\n",
    "> The transposed convolution also called backward convolution since it is the backward propagation of a convolutional layer\n",
    "([Is the deconvolution layer the same as a convolutional layer?,2016](https://arxiv.org/ftp/arxiv/papers/1609/1609.07009.pdf))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452ba1be",
   "metadata": {},
   "source": [
    "### Transpose Convolutional Layer with no padding\n",
    "\n",
    "> if it's assumed that the convolution is non-padded $(p = 0)$ and that its input size $i$ is such that $i − k$ is a multiple of $s$. In that case, the following relationship holds: \n",
    "\n",
    ">Relationship 12. A convolution described by p = 0, k and s and whose input size is such that i−k is a multiple of s, has an associated transposed convolution described by $\\acute{i}, \\acute{k} = k, \\acute{s} = 1 and \\acute{p} = k−1$, where $\\acute{i}$ is the size of the stretched input obtained by adding $s − 1$ zeros between each input unit, and its output size is$$ \\acute{0}=s(\\acute{i}-1)+k $$  [A guide to convolution arithmetic for deep learning,2018](https://arxiv.org/abs/1603.07285)\n",
    "\n",
    "In keras if $i − k$ is not a multiple of $s$ then $$ \\acute{0}=s(\\acute{i}-1)+k +1$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a466f3bb",
   "metadata": {},
   "source": [
    "![Transposed convolution with a $2\\times 2$ kernel. The shaded portions are a portion of an intermediate tensor as well as the input and kernel tensor elements used for the  computation.](../images/trans_conv.svg)\n",
    "\n",
    "Source of image: [ 13.10. Transposed Convolution](http://d2l.ai/chapter_computer-vision/transposed-conv.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f184fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Comp_Trans(conv2d, X):\n",
    "    # Here (1, 1) indicates that the batch size and the number of channels\n",
    "    # are both 1\n",
    "    X=torch.reshape(X,(1,1)+X.shape)\n",
    "    Y=conv2d(X)\n",
    "    # Exclude the first two dimensions that do not interest us: examples and\n",
    "    # channel\n",
    "    return torch.reshape(Y,Y.shape[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca31fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.Tensor([ [0,1.0], [2,3.0]])\n",
    "K=torch.Tensor([[0,1.0], [2,3.0]]).reshape(1,1,2,2)\n",
    "K.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8eb49dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "con2d=torch.nn.ConvTranspose2d(1,1,kernel_size=2)\n",
    "con2d.weight.data=K\n",
    "result=Comp_Trans(con2d,X).round()\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d144e6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sy.Matrix(result.detach_().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b6432e",
   "metadata": {},
   "source": [
    "\n",
    "In the transposed convolution, strides are specified for intermediate results (thus output), not for\n",
    "input. so increasing the stride number will result in an increament in the in the size of the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a034eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "con2d=torch.nn.ConvTranspose2d(1,1,kernel_size=(2,2),stride=(2,2))\n",
    "con2d.weight.data=K\n",
    "result=Comp_Trans(con2d,X).round()\n",
    "print(result.shape)\n",
    "sy.Matrix(result.detach().numpy() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90e7b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.Tensor([[0.0,1, 1.0, 2.0], [3.0, 4.0,0, 5.0], [6.0, 7.0,0, 8.0],[2,3,4,4]])\n",
    "con2d=torch.nn.ConvTranspose2d(1,1,kernel_size=(2,2),stride=(2,2))\n",
    "result=Comp_Trans(con2d,X).round()\n",
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1c47c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "K=torch.Tensor([[0.0,2, 1.0], [2.0, 3,3.0]]).reshape(1,1,2,3)\n",
    "X = torch.Tensor([[0.0,1, 1.0, 2.0], [3.0, 4.0,0, 5.0], [6.0, 7.0,0, 8.0],[2,3,4,4]])\n",
    "con2d=torch.nn.ConvTranspose2d(1,1,kernel_size=(2,3),stride=(2,2))\n",
    "con2d.weight.dataata=K\n",
    "result=Comp_Trans(con2d,X)\n",
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccebaef",
   "metadata": {},
   "source": [
    "# convolutions using matrix multiplications\n",
    "\n",
    "The transposed convolution is named after the matrix transposition. To explain, let us first see how to implement convolutions using matrix multiplications. In the example below, we define a 4 × 4 input $I$ and a 3 × 3 convolution kernel $K$, and then use the Conv2D keras function to compute the convolution output Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc9c7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "I=torch.Tensor([[4,3,2,1],[1,4,3,2],[2,1,4,3.0],[3,2,1,4]])\n",
    "K=torch.Tensor([[0,1.0,0],[-1,2.0,2],[0,1.0,0]]).reshape(1,1,3,3)\n",
    "I.shape,K.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556e2d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "con2d=torch.nn.Conv2d(1,1,kernel_size=(3,3))\n",
    "con2d.weight.data=K\n",
    "Y=Comp_Trans(con2d,I).round()\n",
    "sy.Matrix(Y.detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fabefa",
   "metadata": {},
   "source": [
    "Next, we rewrite the convolution kernel K as a sparse weight matrix W containing a lot of zeros.\n",
    "The shape of the weight matrix is (4, 16), where the non-zero elements come from the convolution kernel K\n",
    "\n",
    "# Note the shape of matrix W is from the input I shape\n",
    "16=4*4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d09813",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=torch.Tensor([1,2,3])\n",
    "a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35703ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel2matrix(K):\n",
    "    k, W = torch.zeros(11), torch.zeros((4, 16))\n",
    "    k[:3], k[4:7],k[8:11] = K[0, :], K[1, :],K[2,:]\n",
    "    W[0, :11], W[1, 1:12], W[2, 4:15], W[3, 5:] = k, k, k, k\n",
    "    return W\n",
    "K=torch.Tensor([[0,1.0,0],[-1,2.0,2],[0,1.0,0]])\n",
    "W = kernel2matrix(K)\n",
    "sy.Matrix(W.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc9d87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "W.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d5558d",
   "metadata": {},
   "source": [
    "Concatenate the input I row by row to get a vector of length 16. Then the matrix multiplication of\n",
    "W and the vectorized I gives a vector of length 4. After reshaping it, we can obtain the same result\n",
    "Y from the original convolution operation above: we just implemented convolutions using matrix multiplications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c524e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.matmul(W,I.reshape(-1)).reshape(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4a98d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd704cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y==torch.matmul(W,I.reshape(-1)).reshape(2,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f125c21e",
   "metadata": {},
   "source": [
    "## implementing transposed convolutions using matrix multiplications\n",
    "\n",
    "\n",
    "Likewise, we can implement transposed convolutions using matrix multiplications. In the following example, we take the 2 × 2 output Y from the above regular convolution as the input to the transposed convolution. To implement this operation by multiplying matrices, we only need to transpose the weight matrix W with the new shape 16 × 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc03b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "K=torch.Tensor([[0,1.0,0],[-1,2.0,2],[0,1.0,0]]).reshape(1,1,3,3)\n",
    "con2d=torch.nn.ConvTranspose2d(1,1,kernel_size=(3,3))\n",
    "con2d.weight.data=K\n",
    "Z=Comp_Trans(con2d,Y).round()\n",
    "Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce019c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.matmul(W.T,Y.reshape(-1)).reshape(4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c77ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "astronaut=sc_data.astronaut()\n",
    "plt.imshow(astronaut)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ea0a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Comp_Mutlti(conv2d, image):\n",
    "    h,w,c=image.shape\n",
    "    img=torch.reshape(image,(c,h,w))\n",
    "    img=np.expand_dims(img,1)\n",
    "    img=torch.Tensor(img)\n",
    "    Y=conv2d(img)\n",
    "    a,b,c,d=Y.shape\n",
    "    return Y.reshape(c,d,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea984bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "astronaut=sc_data.astronaut()\n",
    "astronaut=torch.Tensor(astronaut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c979e684",
   "metadata": {},
   "outputs": [],
   "source": [
    "con2d=torch.nn.ConvTranspose2d(in_channels=1,out_channels=1,kernel_size=(2,2))\n",
    "a=Comp_Mutlti(con2d,astronaut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedc777b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d787d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(a.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e159217f",
   "metadata": {},
   "outputs": [],
   "source": [
    "astronaut=sc_data.astronaut()\n",
    "astronaut.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2774356",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=cv2.resize(astronaut,(512,512))\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3590ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "astronaut=sc_data.astronaut()\n",
    "astronaut=torch.Tensor(astronaut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccb6434",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Comp_Mutlti(conv2d, image):\n",
    "    h,w,c=image.shape\n",
    "    img=torch.reshape(image,(c,h,w))\n",
    "    img=np.expand_dims(img,1)\n",
    "    img=torch.Tensor(img)\n",
    "    Y=conv2d(img)\n",
    "    img_channel,out_channel,height,weight=Y.shape\n",
    "    Y=Y[:1,:]\n",
    "    return Y.reshape(height,weight,out_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d4adea",
   "metadata": {},
   "outputs": [],
   "source": [
    "con2d=torch.nn.ConvTranspose2d(in_channels=1,out_channels=4,kernel_size=(2,2))\n",
    "con2d.weight.data=torch.rand((1,4,2,2))\n",
    "con_imgs=Comp_Mutlti(con2d,astronaut)\n",
    "con_imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161041ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "t=['output_filter_1','output_filter_2','output_filter_3', 'output_filter_4']\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "  \n",
    "for i in range(4):\n",
    "    ax=plt.subplot(1,4,i+1)\n",
    "    ax.imshow(con_imgs[:,:,i].detach().numpy())\n",
    "    ax.set_title(t[i])\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c6db3a",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "[A guide to convolution arithmetic for deep learning,2018](https://arxiv.org/abs/1603.07285)\n",
    "\n",
    "[Is the deconvolution layer the same as a convolutional layer?,2016](https://arxiv.org/ftp/arxiv/papers/1609/1609.07009.pdf)\n",
    "\n",
    "\n",
    "[Fully Convolutional Networks for Semantic Segmentation,2015](https://arxiv.org/pdf/1411.4038.pdf)\n",
    "\n",
    "[Visualizing and Understanding Convolutional Networks,2013](https://arxiv.org/pdf/1311.2901.pdf)\n",
    "\n",
    "[ 13.10. Transposed Convolution](http://d2l.ai/chapter_computer-vision/transposed-conv.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fe8c04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

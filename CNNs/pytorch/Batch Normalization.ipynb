{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Batch-Normalization-layer\" data-toc-modified-id=\"Batch-Normalization-layer-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Batch Normalization layer</a></span></li><li><span><a href=\"#LeNet-5-architecture\" data-toc-modified-id=\"LeNet-5-architecture-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>LeNet-5 architecture</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as f\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "import torch\n",
    "import torch.utils.data as Data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST Dataset\n",
    "train_dataset = datasets.MNIST(root='../data/',train=True,transform=transforms.ToTensor(),download=True)\n",
    "test_dataset = datasets.MNIST(root='../data/',train=False,transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=265\n",
    "train_loader=DataLoader(dataset=train_dataset,batch_size=batch_size,shuffle=True)\n",
    "test_loader=DataLoader(dataset=test_dataset,batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Batch Normalization layer\n",
    "\n",
    "Batch normalization layer is <b>used before the activation layer </b> (according to the authors' original paper), instead of after activation layer.\n",
    "\n",
    "\n",
    "## LeNet-5 architecture\n",
    "we are going to integrate batch normalization into the LeNet-5 architecture displayed below\n",
    "<img src='../images/lenet5.jpg'>\n",
    "\n",
    "\n",
    "<i> (source: Hands-On Computer Vision with TensorFlow 2 (Leverage deep learning to create powerful image processing apps with TensorFlow 2.0 and Keras) by Benjamin Planche Eliot Andres page 94)</i>\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lenet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cov1=nn.Conv2d(1,6,kernel_size=5,padding=2)\n",
    "        self.b2_1=nn.BatchNorm2d(6)\n",
    "        self.max=nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        \n",
    "        self.cov2=nn.Conv2d(6,16,kernel_size=5,padding=2)\n",
    "        self.b2_2=nn.BatchNorm2d(16)\n",
    "        \n",
    "        self.f=nn.Flatten()\n",
    "        self.l1=nn.Linear(16*7*7,120)\n",
    "        self.b1_1=nn.BatchNorm1d(120)\n",
    "        \n",
    "        self.l2=nn.Linear(120,84)\n",
    "        self.b1_2=nn.BatchNorm1d(84)\n",
    "        \n",
    "        self.l3=nn.Linear(84,10)\n",
    "        self.relu=nn.ReLU()\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        #x=x.reshape(-1,1, 28, 28)\n",
    "        h1=self.max(self.relu(self.b2_1(self.cov1(x))))\n",
    "        h2=self.max(self.relu(self.b2_2(self.cov2(h1))))\n",
    "        f=self.f(h2)   \n",
    "        h3=self.relu(self.b1_1(self.l1(f)))\n",
    "        h4=self.relu(self.b1_2(self.l2(h3)))\n",
    "        output=self.l3(h4)\n",
    "        return output\n",
    "lenet=Lenet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(net,data_iterator):\n",
    "    pred_correct = 0\n",
    "    for  data,label in data_iterator:\n",
    "        output=net(data)\n",
    "        pred = output.argmax(dim=1)\n",
    "        pred_correct += (pred==label).float().sum().item()\n",
    "        return pred_correct/len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07547169811320754"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_accuracy(lenet,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn=torch.nn.CrossEntropyLoss()\n",
    "opt=torch.optim.SGD(lenet.parameters(),lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, loss 0.354123,train acc 0.947170,test acc 0.966038\n",
      "epoch 1, loss 0.259338,train acc 0.947170,test acc 0.962264\n",
      "epoch 2, loss 0.151144,train acc 0.969811,test acc 0.984906\n",
      "epoch 3, loss 0.080265,train acc 0.992453,test acc 0.984906\n",
      "epoch 4, loss 0.140203,train acc 0.973585,test acc 0.984906\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 4\n",
    "for epoch in range(num_epochs+1):\n",
    "    test_acc,train_acc=0,0\n",
    "    for X,y in train_loader:\n",
    "        lenet.train()\n",
    "        y_hat=lenet(X)\n",
    "        l=loss_fn(y_hat,y)\n",
    "        opt.zero_grad() \n",
    "        l.backward() \n",
    "        opt.step() \n",
    "    acc_tr=evaluate_accuracy(lenet,train_loader)\n",
    "    lenet.eval()\n",
    "    acc_te=evaluate_accuracy(lenet,test_loader)\n",
    "    test_acc+=acc_te\n",
    "    train_acc+=acc_tr\n",
    "    print('epoch %d, loss %f, train acc %f, test acc %f'%(epoch,l,train_acc,test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

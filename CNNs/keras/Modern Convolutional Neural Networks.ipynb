{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02a6f0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers,models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc15704",
   "metadata": {},
   "source": [
    "## LENET NETWORK\n",
    "<img src='../images/lenet.svg'>\n",
    "<img src='../images/lenet.jpg'>\n",
    "\n",
    "\n",
    " (source: Dive into Deep Learning by Aston Zhang, Zachary C. Lipton, Mu Li, and Alexander J. Smola page 252-3)\n",
    "  \n",
    "\n",
    "To read more on LENET visit :\n",
    "\n",
    "<a href='http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf'>GradientBased Learning Applied to Document Recognition</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8e241a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lenet=keras.models.Sequential([\n",
    "    layers.Conv2D(6,kernel_size=5,padding='same',activation='sigmoid',input_shape=(28,28,1,)),\n",
    "    layers.AvgPool2D(pool_size=2,strides=2),\n",
    "    layers.Conv2D(16,kernel_size=5,activation='sigmoid'),\n",
    "    layers.AvgPool2D(pool_size=2,strides=2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(120,activation='sigmoid'),\n",
    "    layers.Dense(84,activation='sigmoid'),\n",
    "    layers.Dense(10,activation='sigmoid'),\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc1c072",
   "metadata": {},
   "source": [
    "As compared to the original network, we took the liberty of replacing the Gaussian activation in\n",
    "the last layer by a regular dense layer, which tends to be significantly more convenient to train.\n",
    "Other than that, this network matches the historical definition of LeNet5.\n",
    "Next, let us take a look of an example. As shown in Fig. 6.6.2, we feed a single-channel example\n",
    "of size 28 × 28 into the network and perform a forward computation layer by layer printing the\n",
    "output shape at each layer to make sure we understand what is happening here\n",
    "\n",
    "in keras the first convolution layer takes a feature map of size <b>(batch_size , height , width , depth axis)</b >which represent the height, width and the depth axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037eb75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=tf.random.uniform(shape=(1,28,28,1))\n",
    "for layer in lenet.layers:\n",
    "    X=layer(X)\n",
    "    print(layer.__class__.__name__,'output shape: \\t', X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de66f33c",
   "metadata": {},
   "source": [
    "## ALEXNET\n",
    "<img src='../images/alexnet.jpg'>\n",
    " (source: Dive into Deep Learning by Aston Zhang, Zachary C. Lipton, Mu Li, and Alexander J. Smola page 261)\n",
    "  \n",
    "To read more on Alexnet visit :\n",
    "\n",
    "<a href='https://papers.nips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf'>ImageNet Classification with Deep Convolutional\n",
    "Neural Networks\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01c8665",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alexnet():\n",
    "    return tf.keras.models.Sequential([\n",
    "        layers.Conv2D(filters=96,kernel_size=11,strides=4,activation='relu'),\n",
    "        layers.MaxPool2D(pool_size=3,strides=2),\n",
    "        layers.Conv2D(filters=256,kernel_size=5,padding='same',activation='relu'),\n",
    "        layers.MaxPool2D(pool_size=3,strides=2),\n",
    "        layers.Conv2D(filters=384,kernel_size=3,padding='same',activation='relu'),\n",
    "        layers.Conv2D(filters=384,kernel_size=3,padding='same',activation='relu'),\n",
    "        layers.Conv2D(filters=384,kernel_size=3,padding='same',activation='relu'),\n",
    "        layers.MaxPool2D(pool_size=3,strides=2),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(4096,activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(4096,activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(10)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92f2856",
   "metadata": {},
   "source": [
    "We construct a single-channel data instance with both height and width of 224 to observe the output shape of each layer. It matches our diagram above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109c94c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.random.uniform(shape=(1, 224, 224,1))\n",
    "for layer in alexnet().layers:\n",
    "    X = layer(X)\n",
    "    print(layer.__class__.__name__, 'output shape:\\t', X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7bfe46",
   "metadata": {},
   "source": [
    "## VGG Blocks\n",
    "<img src='../images/vvg.jpg'>\n",
    "The function takes two arguments corresponding to the number of convolutional layers num_convs and the number of output channels num_channels\n",
    "\n",
    "\n",
    "To read more on VGG visit :\n",
    "\n",
    "<a href='https://arxiv.org/pdf/1409.1556.pdf'>VERY DEEP CONVOLUTIONAL NETWORKS FOR LARGE-SCALE IMAGE RECOGNITION</a>\n",
    "\n",
    "<img src='../images/vgg.png'>\n",
    "The original VGG network had 5 convolutional blocks, among which the first two have one convolutional layer each and the latter three contain two convolutional layers each but we will implement the vgg diagram above of which the first two have two convolutional layer each and the latter three contain three convolutional layers each.\n",
    "\n",
    "The first block has 64 output channels and each subsequent block doubles the number of output channels, until that number reaches 512. Since this network uses 8 convolutional layers and 3 fully-connected layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d879a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg_1():\n",
    "    return tf.keras.models.Sequential([\n",
    "        layers.Conv2D(filters=64,kernel_size=3,padding='same',activation='relu'),\n",
    "        layers.Conv2D(filters=64,kernel_size=3,padding='same',activation='relu'),\n",
    "        layers.MaxPool2D(pool_size=2,strides=2),\n",
    "        \n",
    "        layers.Conv2D(128,kernel_size=3,padding='same',activation='relu'),\n",
    "        layers.Conv2D(128,kernel_size=3,padding='same',activation='relu'),\n",
    "        layers.MaxPool2D(pool_size=2,strides=2),\n",
    "        \n",
    "        layers.Conv2D(256,kernel_size=3,padding='same',activation='relu'),\n",
    "        layers.Conv2D(256,kernel_size=3,padding='same',activation='relu'),\n",
    "        layers.Conv2D(256,kernel_size=3,padding='same',activation='relu'),\n",
    "        layers.MaxPool2D(pool_size=2,strides=2),\n",
    "        \n",
    "        layers.Conv2D(512,kernel_size=3,padding='same',activation='relu'),\n",
    "        layers.Conv2D(512,kernel_size=3,padding='same',activation='relu'),\n",
    "        layers.Conv2D(512,kernel_size=3,padding='same',activation='relu'),\n",
    "        layers.MaxPool2D(pool_size=2,strides=2),\n",
    "        \n",
    "        layers.Conv2D(512,kernel_size=3,padding='same',activation='relu'),\n",
    "        layers.Conv2D(512,kernel_size=3,padding='same',activation='relu'),\n",
    "        layers.Conv2D(512,kernel_size=3,padding='same',activation='relu'),\n",
    "        layers.MaxPool2D(pool_size=2,strides=2),\n",
    "        \n",
    "        layers.Flatten(),\n",
    "        layers.Dense(4096,activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(4096,activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(10)\n",
    "        \n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7ee3b0",
   "metadata": {},
   "source": [
    "# Or implemented as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49ddc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg_block(num_convs,filters):\n",
    "    blk=tf.keras.models.Sequential()\n",
    "    for _ in range(num_convs):\n",
    "        blk.add(layers.Conv2D(filters,kernel_size=3,padding='same',activation='relu'))\n",
    "    blk.add(layers.MaxPool2D(pool_size=2,strides=2))\n",
    "    return blk\n",
    "\n",
    "conv_arch = ((2, 64), (2, 128), (3, 256), (3, 512), (3, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ba8386",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg(conv_arch):\n",
    "    blk=tf.keras.models.Sequential()\n",
    "    for (num_convs,filters) in conv_arch:\n",
    "        blk.add(vgg_block(num_convs,filters))\n",
    "    blk.add(layers.Flatten())\n",
    "    blk.add(layers.Dense(4096,activation='relu'))\n",
    "    blk.add(layers.Dropout(0.5))\n",
    "    blk.add(layers.Dense(4096,activation='relu'))\n",
    "    blk.add(layers.Dropout(0.5))\n",
    "    blk.add(layers.Dense(10))\n",
    "    return blk\n",
    "\n",
    "vgg_2 = vgg(conv_arch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a32e499",
   "metadata": {},
   "source": [
    "Next, we will construct a single-channel data example with a height and width of 224 to observe\n",
    "the output shape of each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02db61e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.random.uniform(shape=(1, 224, 224,1))\n",
    "for layer in vgg_1().layers:\n",
    "    X = layer(X)\n",
    "    print(layer.__class__.__name__, 'output shape:\\t', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b05a8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.random.uniform(shape=(1, 224, 224,1))\n",
    "for layer in vgg_2.layers:\n",
    "    X = layer(X)\n",
    "    print(layer.__class__.__name__, 'output shape:\\t', X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7866ec",
   "metadata": {},
   "source": [
    "##  Network in Network (NiN) BLOCK\n",
    "<img src='../images/nin.jpg'/>\n",
    "The NiN block consists of one convolutional layer followed by two 1 × 1 convolutional layers that\n",
    "act as per-pixel fully-connected layers with ReLU activations. The convolution width of the first\n",
    "layer is typically set by the user. The subsequent widths are fixed to 1 × 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63138d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nin_block(filters, kernel_size, strides,padding):\n",
    "    return tf.keras.models.Sequential([\n",
    "        layers.Conv2D(filters,kernel_size,strides,padding,activation='relu'),\n",
    "        layers.Conv2D(filters,kernel_size=1,activation='relu'),\n",
    "         layers.Conv2D(filters,kernel_size=1,activation='relu')    \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2878cb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def nin():\n",
    "    return tf.keras.models.Sequential([\n",
    "        nin_block(filters=96,kernel_size=11,strides=4,padding='valid'),\n",
    "        layers.MaxPool2D(pool_size=3,strides=2),\n",
    "        \n",
    "        nin_block(filters=256,kernel_size=5,strides=1,padding='same'),\n",
    "        layers.MaxPool2D(pool_size=3,strides=2),\n",
    "        \n",
    "        nin_block(filters=384,kernel_size=5,strides=1,padding='same'),\n",
    "        layers.MaxPool2D(pool_size=3, strides=2),\n",
    "        layers.Dropout(0.5),\n",
    "        \n",
    "        nin_block(filters=10,kernel_size=3,strides=1,padding='same'),\n",
    "        layers.GlobalAvgPool2D(),\n",
    "        tf.keras.layers.Reshape((1, 1, 10)),\n",
    "        layers.Flatten()\n",
    "        \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705bdb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.random.uniform(shape=(1, 224, 224,1))\n",
    "for layer in nin().layers:\n",
    "    X = layer(X)\n",
    "    print(layer.__class__.__name__, 'output shape:\\t', X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e42daf",
   "metadata": {},
   "source": [
    "## INCEPTION\n",
    "<img src=\"../images/inception.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d7e9c1",
   "metadata": {},
   "source": [
    "GoogLeNet uses a stack of a total of 9 inception blocks and global average pooling to generate its estimates. Maximum pooling between inception blocks reduced the\n",
    "dimensionality. The first part is identical to AlexNet and LeNet, the stack of blocks is inherited\n",
    "from VGG and the global average pooling avoids a stack of fully-connected layers at the end. The\n",
    "architecture is depicted below\n",
    "<img src=\"../images/inception1.jpg\" />\n",
    "<img src=\"../images/inception2.jpg\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "59822d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inception_block(tf.keras.Model):\n",
    "    def __init__(self,c1,c2,c3,c4,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        # Path 1 is a single 1 x 1 convolutional layer\n",
    "        self.p1_1=layers.Conv2D(filters=c1,kernel_size=1,activation='relu')\n",
    "        # Path 2 is a 1 x 1 convolutional layer followed by a 3 x 3\n",
    "        # convolutional layer\n",
    "        self.p2_1=layers.Conv2D(filters=c2[0],kernel_size=1,activation='relu')\n",
    "        self.p2_2=layers.Conv2D(filters=c2[1],kernel_size=3,padding='same',activation='relu')\n",
    "         # Path 2 is a 1 x 1 convolutional layer followed by a 5 x 5\n",
    "        # convolutional layer\n",
    "        self.p3_1=layers.Conv2D(filters=c3[0],kernel_size=1,activation='relu')\n",
    "        self.p3_2=layers.Conv2D(filters=c3[1],kernel_size=5,padding='same',activation='relu')\n",
    "         # Path 4 is a 3 x 3 maximum pooling layer followed by a 1 x 1\n",
    "        # convolutional layer\n",
    "        self.p4_1=layers.MaxPool2D(pool_size=3,padding='same',strides=1)\n",
    "        self.p4_2=layers.Conv2D(filters=c4,kernel_size=1,activation='relu')\n",
    "    def call(self,x):\n",
    "        p1=self.p1_1(x)\n",
    "        p2=self.p2_2(self.p2_1(x))\n",
    "        p3=self.p3_2(self.p3_1(x))\n",
    "        p4=self.p4_2(self.p4_1(x))\n",
    "        return layers.Concatenate()([p1, p2, p3, p4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d79d9393",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception():\n",
    "    return tf.keras.models.Sequential([\n",
    "        layers.Conv2D(filters=64,kernel_size=7,strides=2,padding='same',activation='relu'),\n",
    "        layers.MaxPool2D(pool_size=3,padding='same',strides=2),\n",
    "        \n",
    "        layers.Conv2D(64,kernel_size=1,activation='relu'),\n",
    "        layers.Conv2D(192,kernel_size=3,padding='same',activation='relu'),\n",
    "        layers.MaxPool2D(pool_size=3,padding='same',strides=2),\n",
    "        # inception(3a)\n",
    "        Inception_block(c1=64,c2=(96,128),c3=(16,32),c4=32),\n",
    "               # inception(3b)\n",
    "        Inception_block(c1=128,c2=(128,192),c3=(32,96),c4=64),\n",
    "        layers.MaxPool2D(pool_size=3,padding='same',strides=2),\n",
    "        # inception(4a)\n",
    "        Inception_block(c1=192,c2=(96,208),c3=(16,48),c4=64),\n",
    "              # inception(4b)\n",
    "        Inception_block(c1=160,c2=(112,224),c3=(24,64),c4=64),\n",
    "        # inception(4c)\n",
    "        Inception_block(c1=128,c2=(128,256),c3=(24,64),c4=64),\n",
    "        # inception(4d)\n",
    "        Inception_block(112,(144,288),(32,64),64),\n",
    "        # inception(4e)\n",
    "        Inception_block(256,(160,320),(32,128),128),\n",
    "        layers.MaxPool2D(pool_size=3,padding='same',strides=2),\n",
    "         # inception(5a)\n",
    "        Inception_block(256, (160, 320), (32, 128), 128),\n",
    "              # inception(5b)\n",
    "        Inception_block(384, (192, 384), (48, 128), 128),\n",
    "        layers.MaxPool2D(pool_size=3,padding='same',strides=2),\n",
    "        layers.GlobalAvgPool2D(),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.4),\n",
    "        layers.Dense(10,activation='softmax')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "86c751e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2D output shape:\t (1, 1, 48, 64)\n",
      "MaxPooling2D output shape:\t (1, 1, 24, 64)\n",
      "Conv2D output shape:\t (1, 1, 24, 64)\n",
      "Conv2D output shape:\t (1, 1, 24, 192)\n",
      "MaxPooling2D output shape:\t (1, 1, 12, 192)\n",
      "Inception_block output shape:\t (1, 1, 12, 256)\n",
      "Inception_block output shape:\t (1, 1, 12, 480)\n",
      "MaxPooling2D output shape:\t (1, 1, 6, 480)\n",
      "Inception_block output shape:\t (1, 1, 6, 512)\n",
      "Inception_block output shape:\t (1, 1, 6, 512)\n",
      "Inception_block output shape:\t (1, 1, 6, 512)\n",
      "Inception_block output shape:\t (1, 1, 6, 528)\n",
      "Inception_block output shape:\t (1, 1, 6, 832)\n",
      "MaxPooling2D output shape:\t (1, 1, 3, 832)\n",
      "Inception_block output shape:\t (1, 1, 3, 832)\n",
      "Inception_block output shape:\t (1, 1, 3, 1024)\n",
      "MaxPooling2D output shape:\t (1, 1, 2, 1024)\n",
      "GlobalAveragePooling2D output shape:\t (1, 1024)\n",
      "Flatten output shape:\t (1, 1024)\n",
      "Dropout output shape:\t (1, 1024)\n",
      "Dense output shape:\t (1, 10)\n"
     ]
    }
   ],
   "source": [
    "X = tf.random.uniform(shape=(1, 1, 96, 96))\n",
    "for layer in inception().layers:\n",
    "    X = layer(X)\n",
    "    print(layer.__class__.__name__, 'output shape:\\t', X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebaee71",
   "metadata": {},
   "source": [
    "# RESNET\n",
    "<p>To understand how resnet work read </p>\n",
    "<a href='https://arxiv.org/pdf/1512.03385.pdf'>Deep Residual Learning for Image Recognition<a/>\n",
    "    \n",
    "<a href='https://arxiv.org/pdf/1603.05027.pdf'>Identity Mappings in Deep Residual Networks</a>\n",
    "<img src=\"../images/resnet.jpg\"  width='1000px'>\n",
    "Source:  <a href='https://arxiv.org/pdf/1512.03385.pdf'>Deep Residual Learning for Image Recognition<a/>\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c2677963",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Residual(keras.models.Model):\n",
    "    def __init__(self,num_filters,stride=1,downsample=False,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.cov1=layers.Conv2D(num_filters,kernel_size=3,strides=stride,padding='same')\n",
    "        self.cov2=layers.Conv2D(num_filters,kernel_size=3,padding='same')\n",
    "        if downsample:\n",
    "            self.downsample=layers.Conv2D(num_filters,kernel_size=1,strides=stride)\n",
    "        else:\n",
    "            self.downsample=None\n",
    "        self.bn1=layers.BatchNormalization()\n",
    "        self.bn2=layers.BatchNormalization()\n",
    "        self.relu=layers.ReLU()\n",
    "    def call(self,x):\n",
    "        hx=self.relu(self.bn1(self.cov1(x)))\n",
    "        hx=self.bn2(self.cov2(hx))\n",
    "        if self.downsample:\n",
    "            x=self.downsample(x)\n",
    "        return self.relu(x+hx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ec868592",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_block(num_filters,num_residuals,first_block=False):\n",
    "    blk=models.Sequential()\n",
    "    for residual in range(num_residuals):\n",
    "        if residual==0 and not first_block:\n",
    "            blk.add(Residual(num_filters=num_filters,downsample=True,stride=2))\n",
    "        else:\n",
    "            blk.add(Residual(num_filters=num_filters))\n",
    "    return blk\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7127bf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet34=models.Sequential([\n",
    "          layers.Conv2D(64,kernel_size=7,strides=2,padding='same'),\n",
    "          layers.BatchNormalization(),\n",
    "          layers.Activation('relu'),\n",
    "          layers.MaxPool2D(pool_size=3,strides=2,padding='same'),\n",
    "          resnet_block(64,3,first_block=True),\n",
    "          resnet_block(128,4),\n",
    "          resnet_block(256,6),\n",
    "          resnet_block(512,3),\n",
    "          layers.GlobalAvgPool2D(),\n",
    "          layers.Flatten(),\n",
    "          layers.Dense(10)\n",
    "         ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ca34316c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2D output shape:\t (1, 112, 112, 64)\n",
      "BatchNormalization output shape:\t (1, 112, 112, 64)\n",
      "Activation output shape:\t (1, 112, 112, 64)\n",
      "MaxPooling2D output shape:\t (1, 56, 56, 64)\n",
      "Sequential output shape:\t (1, 56, 56, 64)\n",
      "Sequential output shape:\t (1, 28, 28, 128)\n",
      "Sequential output shape:\t (1, 14, 14, 256)\n",
      "Sequential output shape:\t (1, 7, 7, 512)\n",
      "GlobalAveragePooling2D output shape:\t (1, 512)\n",
      "Flatten output shape:\t (1, 512)\n",
      "Dense output shape:\t (1, 10)\n"
     ]
    }
   ],
   "source": [
    "X = tf.random.uniform(shape=(1, 224, 224,1))\n",
    "for layer in resnet34.layers:\n",
    "    X = layer(X)\n",
    "    print(layer.__class__.__name__, 'output shape:\\t', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42306d1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc59681",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#A-Custom-Block\" data-toc-modified-id=\"A-Custom-Block-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>A Custom Block</a></span></li><li><span><a href=\"#The-Sequential-Block\" data-toc-modified-id=\"The-Sequential-Block-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>The Sequential Block</a></span></li><li><span><a href=\"#Executing-Code-in-the-forward-Method\" data-toc-modified-id=\"Executing-Code-in-the-forward-Method-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Executing Code in the forward Method</a></span></li><li><span><a href=\"#PARAMETER\" data-toc-modified-id=\"PARAMETER-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>PARAMETER</a></span></li><li><span><a href=\"#Parameter-Access\" data-toc-modified-id=\"Parameter-Access-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Parameter Access</a></span></li><li><span><a href=\"#Targeted-Parameters\" data-toc-modified-id=\"Targeted-Parameters-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Targeted Parameters</a></span></li><li><span><a href=\"#All-Parameters-at-Once\" data-toc-modified-id=\"All-Parameters-at-Once-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>All Parameters at Once</a></span></li><li><span><a href=\"#Collecting-Parameters-from-Nested-Blocks\" data-toc-modified-id=\"Collecting-Parameters-from-Nested-Blocks-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Collecting Parameters from Nested Blocks</a></span></li><li><span><a href=\"#Parameter-Initialization\" data-toc-modified-id=\"Parameter-Initialization-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Parameter Initialization</a></span></li><li><span><a href=\"#Custom-Initialization\" data-toc-modified-id=\"Custom-Initialization-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Custom Initialization</a></span></li><li><span><a href=\"#Tied-Parameters\" data-toc-modified-id=\"Tied-Parameters-11\"><span class=\"toc-item-num\">11&nbsp;&nbsp;</span>Tied Parameters</a></span></li><li><span><a href=\"#Loading-and-Saving-Tensors\" data-toc-modified-id=\"Loading-and-Saving-Tensors-12\"><span class=\"toc-item-num\">12&nbsp;&nbsp;</span>Loading and Saving Tensors</a></span></li><li><span><a href=\"#Loading-and-Saving-Model-Parameters\" data-toc-modified-id=\"Loading-and-Saving-Model-Parameters-13\"><span class=\"toc-item-num\">13&nbsp;&nbsp;</span>Loading and Saving Model Parameters</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet\n",
    "from mxnet import gluon\n",
    "from mxnet.gluon import nn\n",
    "from mxnet import  np,npx\n",
    "npx.set_np()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T02:48:36.550492Z",
     "start_time": "2020-07-01T02:48:31.394453Z"
    }
   },
   "source": [
    "## A Custom Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Block):\n",
    "    def __init__(self,*kwargs):\n",
    "        super().__init__(*kwargs)\n",
    "        self.lr1=nn.Dense(50,activation='relu')\n",
    "        self.lr2=nn.Dense(20,activation='relu')\n",
    "        self.l3=nn.Dense(1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        h1=self.lr1(x)\n",
    "        h2=self.lr2(h1)\n",
    "        output=self.l3(h2)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5488135 , 0.5928446 , 0.71518934],\n",
       "       [0.84426576, 0.60276335, 0.8579456 ],\n",
       "       [0.5448832 , 0.8472517 , 0.4236548 ],\n",
       "       [0.6235637 , 0.6458941 , 0.3843817 ],\n",
       "       [0.4375872 , 0.2975346 , 0.891773  ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.uniform(size=(5,3))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "net=MLP()\n",
    "net.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00207408],\n",
       "       [-0.00273135],\n",
       "       [-0.00165528],\n",
       "       [-0.00164686],\n",
       "       [-0.00209926]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "        Layer (type)                                Output Shape         Param #\n",
      "================================================================================\n",
      "               Input                                      (5, 3)               0\n",
      "        Activation-1                                     (5, 50)               0\n",
      "             Dense-2                                     (5, 50)             200\n",
      "        Activation-3                                     (5, 20)               0\n",
      "             Dense-4                                     (5, 20)            1020\n",
      "             Dense-5                                      (5, 1)              21\n",
      "               MLP-6                                      (5, 1)               0\n",
      "================================================================================\n",
      "Parameters in forward computation graph, duplicate included\n",
      "   Total params: 1241\n",
      "   Trainable params: 1241\n",
      "   Non-trainable params: 0\n",
      "Shared params in forward computation graph: 0\n",
      "Unique parameters in model: 1241\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "net.summary(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4*500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1020"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "51*20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(nn.Block):\n",
    "    def __init__(self,in_units,units):\n",
    "        super().__init__()\n",
    "        with self.name_scope():\n",
    "            self.units=units\n",
    "            self.in_units=in_units\n",
    "            self.weight=self.params.get('weight',init=mxnet.init.Normal(sigma=0.5),\n",
    "                                    shape=(self.in_units,self.units))\n",
    "            self.bias=self.params.get('bias',init=mxnet.init.Normal(sigma=0.5),shape=(self.units))\n",
    "    def forward(self,x):\n",
    "        liner=np.dot(x,self.weight.data())+self.bias.data()\n",
    "        output=npx.relu(liner)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Block):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1=Linear(units=7,in_units=3)\n",
    "        self.l2=Linear(units=2,in_units=7)\n",
    "        self.l3=Linear(units=4,in_units=2)\n",
    "    def forward(self,x):\n",
    "        h1=npx.relu(self.l1(x))\n",
    "        h1=npx.dropout(data=h1,p=0.5)\n",
    "        h2=npx.relu(self.l2(h1))\n",
    "        output=self.l3(h2)\n",
    "        return output    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp=MLP()\n",
    "mlp.collect_params().initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.rand(5,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mlp1_ (\n",
       "  Parameter linear0_weight (shape=(3, 7), dtype=<class 'numpy.float32'>)\n",
       "  Parameter linear0_bias (shape=(7,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter linear1_weight (shape=(7, 2), dtype=<class 'numpy.float32'>)\n",
       "  Parameter linear1_bias (shape=(2,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter linear2_weight (shape=(2, 4), dtype=<class 'numpy.float32'>)\n",
       "  Parameter linear2_bias (shape=(4,), dtype=<class 'numpy.float32'>)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.collect_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.90511256,  0.1217143 ,  0.11279303, -0.9587378 ,  1.2084526 ,\n",
       "        -0.36452514,  0.7567334 ],\n",
       "       [-0.6180372 ,  0.5950067 , -0.62458515, -0.5837988 ,  0.50898963,\n",
       "         0.3497631 ,  0.08811765],\n",
       "       [-0.97152925, -0.11385177, -0.3536062 , -0.7891857 ,  0.33093628,\n",
       "        -0.650588  ,  0.49574193]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.collect_params()['linear0_weight'].data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.7017477 , 0.        , 0.06274574],\n",
       "       [0.        , 0.71423846, 0.        , 0.15500778],\n",
       "       [0.        , 0.45687222, 0.        , 0.1652804 ],\n",
       "       [0.        , 0.68415844, 0.        , 0.01396903],\n",
       "       [0.        , 0.72619736, 0.        , 0.07520926]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDense(nn.Block):\n",
    "    def __init__(self, units, in_units, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.weight = self.params.get('weight', shape=(in_units, units))\n",
    "        self.bias = self.params.get('bias', shape=(units,))\n",
    "    def forward(self, x):\n",
    "        linear = np.dot(x, self.weight.data(ctx=x.ctx)) + self.bias.data(ctx=x.ctx)\n",
    "        return npx.relu(linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential()\n",
    "net.add(MyDense(8, in_units=6),\n",
    "MyDense(4, in_units=8))\n",
    "net.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01086344, 0.        , 0.03279249, 0.02536564],\n",
       "       [0.00875435, 0.        , 0.0257882 , 0.02083994]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(np.random.uniform(size=(2, 6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Sequential Block\n",
    "\n",
    "The following MySequential class delivers the same functionality as Gluonʼs default Sequential\n",
    "class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySequential(nn.Block):\n",
    "    def add(self, block):\n",
    "        # Here, block is an instance of a Block subclass, and we assume it has\n",
    "        # a unique name. We save it in the member variable _children of the\n",
    "        # Block class, and its type is OrderedDict. When the MySequential\n",
    "        # instance calls the initialize function, the system automatically\n",
    "        # initializes all members of _children\n",
    "        self._children[block.name] = block\n",
    "    def forward(self, x):\n",
    "        # OrderedDict guarantees that members will be traversed in the order\n",
    "        # they were added\n",
    "        for block in self._children.values():\n",
    "            x = block(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "net=MySequential()\n",
    "net.add(nn.Dense(50,activation='relu'))\n",
    "net.add(nn.Dense(20,activation='relu'))\n",
    "net.add(nn.Dense(1))\n",
    "net.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00104705],\n",
       "       [0.00077609],\n",
       "       [0.00030453],\n",
       "       [0.00107107],\n",
       "       [0.00115779]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executing Code in the forward Method\n",
    "<h1><kbd>\n",
    "You might have noticed that until now, all of the operations in our networks have acted upon our networkʼs activations and its parameters. Sometimes, however, we might want to incorporate constant terms which are neither the result of previous layers nor updatable parameters. In Gluon, we call these constant parameters. Say for example that we want a layer that calculates the function  f(x; w) = c · w⊤x, where x is the input, w is our parameter, and c is some specified constant that is not updated during optimization.\n",
    "Declaring constants explicitly (via get_constant) makes this clear helps Gluon to speed up execution. In the following code, we will implement a model that could not easily be assembled using\n",
    "only predefined layers and Sequential\n",
    "    \n",
    "    (source: Dive into Deep Learning by Aston Zhang, Zachary C. Lipton, Mu Li, and Alexander J. Smola page 202)\n",
    "</kbd></h1>\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FixedHiddenMLP(nn.Block):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(FixedHiddenMLP, self).__init__(**kwargs)\n",
    "        # Random weight parameters created with the get_constant are not\n",
    "        # iterated during training (i.e., constant parameters)\n",
    "        self.rand_weight = self.params.get_constant('rand_weight',np.random.uniform(size=(5, 2)))\n",
    "        self.dense = nn.Dense(5, activation='relu')\n",
    "    def forward(self,x):\n",
    "        x=self.dense(x)\n",
    "        x=npx.relu(np.dot(x,self.rand_weight.data()))\n",
    "        while np.abs(x).mean()>1:\n",
    "            x/=3\n",
    "        return x.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "net =FixedHiddenMLP()\n",
    "net.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.0040905 , 0.00340335])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PARAMETER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = nn.Sequential()\n",
    "network.add(nn.Dense(5, activation='relu'))\n",
    "network.add(nn.Dense(3, activation='relu'))\n",
    "network.add(nn.Dense(10))\n",
    "network.initialize() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.5490829e-06,  1.1651800e-05, -1.2539108e-05,  1.6888396e-05,\n",
       "         1.8220503e-06,  4.1542698e-06, -1.5352751e-05, -5.7152911e-06,\n",
       "        -1.0659906e-05,  1.6679809e-05],\n",
       "       [-6.8636573e-06,  6.6575398e-05, -8.8636894e-05,  3.2865614e-04,\n",
       "         1.3288157e-04,  6.8365924e-05, -3.8826469e-04,  1.1464535e-04,\n",
       "        -1.4936542e-05,  1.9356799e-04]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.uniform(size=(2, 4))\n",
    "network(x) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Block.load_params of Sequential(\n",
       "  (0): Dense(4 -> 5, Activation(relu))\n",
       "  (1): Dense(5 -> 3, Activation(relu))\n",
       "  (2): Dense(3 -> 10, linear)\n",
       ")>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.load_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense7_ (\n",
      "  Parameter dense7_weight (shape=(5, 4), dtype=float32)\n",
      "  Parameter dense7_bias (shape=(5,), dtype=float32)\n",
      ")\n",
      "dense8_ (\n",
      "  Parameter dense8_weight (shape=(3, 5), dtype=float32)\n",
      "  Parameter dense8_bias (shape=(3,), dtype=float32)\n",
      ")\n",
      "dense9_ (\n",
      "  Parameter dense9_weight (shape=(10, 3), dtype=float32)\n",
      "  Parameter dense9_bias (shape=(10,), dtype=float32)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(network[0].params)\n",
    "print(network[1].params)\n",
    "print(network[2].params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Targeted Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accessing the values of the bias parameter of the first layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'mxnet.gluon.parameter.Parameter'>\n",
      "Parameter dense7_bias (shape=(5,), dtype=float32)\n",
      "[0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(type(network[0].bias))\n",
    "print(network[0].bias)\n",
    "print(network[0].bias.data())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accessing the weight of the second layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter dense8_weight (shape=(3, 5), dtype=float32)\n",
      "[[-0.03604563  0.06130102  0.00140283  0.01695964 -0.03465375]\n",
      " [-0.05630658  0.02086442  0.05381045  0.0262625   0.03768177]\n",
      " [-0.06403377  0.02966186  0.00689322 -0.06247731  0.02004783]]\n"
     ]
    }
   ],
   "source": [
    "print(network[1].weight)\n",
    "print(network[1].weight.data())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the value, each parameter also allows us to access the gradient. Because we have\n",
    "not invoked backpropagation for this network yet, it is in its initial state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(network[1].weight.grad())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Parameters at Once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense7_ (\n",
      "  Parameter dense7_weight (shape=(5, 4), dtype=float32)\n",
      "  Parameter dense7_bias (shape=(5,), dtype=float32)\n",
      ")\n",
      "sequential1_ (\n",
      "  Parameter dense7_weight (shape=(5, 4), dtype=float32)\n",
      "  Parameter dense7_bias (shape=(5,), dtype=float32)\n",
      "  Parameter dense8_weight (shape=(3, 5), dtype=float32)\n",
      "  Parameter dense8_bias (shape=(3,), dtype=float32)\n",
      "  Parameter dense9_weight (shape=(10, 3), dtype=float32)\n",
      "  Parameter dense9_bias (shape=(10,), dtype=float32)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(network[0].collect_params())\n",
    "print(network.collect_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.02726193,  0.04634436, -0.06751239,  0.02247506],\n",
       "       [ 0.0641404 , -0.04866897,  0.04530007,  0.06944998],\n",
       "       [ 0.05894835, -0.05596732, -0.03630256,  0.05139603],\n",
       "       [ 0.02638481, -0.02880274,  0.06674667, -0.00905051],\n",
       "       [-0.05220781,  0.04136392,  0.03453634,  0.02485117]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.collect_params()['dense7_weight'].data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.02726193,  0.04634436, -0.06751239,  0.02247506],\n",
       "       [ 0.0641404 , -0.04866897,  0.04530007,  0.06944998],\n",
       "       [ 0.05894835, -0.05596732, -0.03630256,  0.05139603],\n",
       "       [ 0.02638481, -0.02880274,  0.06674667, -0.00905051],\n",
       "       [-0.05220781,  0.04136392,  0.03453634,  0.02485117]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network[0].weight.data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting Parameters from Nested Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def block1():\n",
    "    net=nn.Sequential()\n",
    "    net.add(nn.Dense(10,activation='relu'))\n",
    "    net.add(nn.Dense(5,activation='relu'))\n",
    "    return net\n",
    "def block2():\n",
    "    net=nn.Sequential()\n",
    "    for _ in range(3):\n",
    "        net.add(block1())\n",
    "    return net\n",
    "rgnet = nn.Sequential()\n",
    "rgnet.add(block2())\n",
    "rgnet.add(nn.Dense(1))\n",
    "rgnet.initialize()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.06512146, 0.55264586, 0.04457111],\n",
       "       [0.2512001 , 0.9132836 , 0.32405233],\n",
       "       [0.3050467 , 0.7881646 , 0.5579874 ],\n",
       "       [0.16245073, 0.9824449 , 0.08158111],\n",
       "       [0.40044853, 0.5131847 , 0.6658714 ]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.uniform(size=(5,3))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.2800735e-09],\n",
       "       [-5.1647358e-09],\n",
       "       [-3.2364771e-09],\n",
       "       [-6.0090639e-09],\n",
       "       [-9.3335528e-10]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgnet(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# let see how the network is organized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Block.collect_params of Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Dense(3 -> 10, Activation(relu))\n",
      "      (1): Dense(10 -> 5, Activation(relu))\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Dense(5 -> 10, Activation(relu))\n",
      "      (1): Dense(10 -> 5, Activation(relu))\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Dense(5 -> 10, Activation(relu))\n",
      "      (1): Dense(10 -> 5, Activation(relu))\n",
      "    )\n",
      "  )\n",
      "  (1): Dense(5 -> 1, linear)\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "print(rgnet.collect_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequential2_ (\n",
      "  Parameter dense10_weight (shape=(10, 3), dtype=float32)\n",
      "  Parameter dense10_bias (shape=(10,), dtype=float32)\n",
      "  Parameter dense11_weight (shape=(5, 10), dtype=float32)\n",
      "  Parameter dense11_bias (shape=(5,), dtype=float32)\n",
      "  Parameter dense12_weight (shape=(10, 5), dtype=float32)\n",
      "  Parameter dense12_bias (shape=(10,), dtype=float32)\n",
      "  Parameter dense13_weight (shape=(5, 10), dtype=float32)\n",
      "  Parameter dense13_bias (shape=(5,), dtype=float32)\n",
      "  Parameter dense14_weight (shape=(10, 5), dtype=float32)\n",
      "  Parameter dense14_bias (shape=(10,), dtype=float32)\n",
      "  Parameter dense15_weight (shape=(5, 10), dtype=float32)\n",
      "  Parameter dense15_bias (shape=(5,), dtype=float32)\n",
      "  Parameter dense16_weight (shape=(1, 5), dtype=float32)\n",
      "  Parameter dense16_bias (shape=(1,), dtype=float32)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(rgnet.collect_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(rgnet[0][0][1].bias.data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(rgnet[0][0][0].bias.data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.06793067 -0.02857513  0.04238271 -0.02753913  0.0159183  -0.02017552\n",
      "   0.03580332  0.04344229 -0.01702353  0.01086262]\n",
      " [ 0.01413071 -0.05946118 -0.00431622 -0.05904555  0.03154427 -0.01801983\n",
      "  -0.05632765  0.03732275 -0.05355117  0.02641568]\n",
      " [ 0.04385129  0.02911753 -0.05524785  0.03740941  0.06503151 -0.02979862\n",
      "   0.02976952  0.00675588  0.00335923  0.00606937]\n",
      " [ 0.05405652  0.03354855  0.05086622  0.06396187  0.03855976 -0.03108141\n",
      "   0.04162101  0.04105943  0.03940867  0.02239587]\n",
      " [ 0.00975884  0.0112333   0.03175914  0.03848317 -0.00599905  0.06216455\n",
      "   0.04231021 -0.0648632   0.03409437 -0.04936399]]\n"
     ]
    }
   ],
   "source": [
    "print(rgnet[0][0][1].weight.data())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Built-in Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Here `force_reinit` ensures that parameters are freshly initialized even if\n",
    "# they were already initialized previously\n",
    "network.initialize(init=mxnet.init.Normal(sigma=0.01),force_reinit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01143898, -0.00064168,  0.00557283, -0.00845679],\n",
       "       [ 0.00498488, -0.004527  , -0.00650531,  0.00110566],\n",
       "       [-0.01809649, -0.00372469,  0.00590213, -0.00047768],\n",
       "       [ 0.01075142, -0.01239304,  0.00349711,  0.00102358],\n",
       "       [ 0.02841117, -0.01567159, -0.00675081, -0.01355863]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network[0].weight.data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.02841117, -0.01567159, -0.00675081, -0.01355863])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network[0].weight.data()[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> initializing all parameters to a given constant value 0.5</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.initialize(init=mxnet.init.Constant(0.5),force_reinit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5, 0.5, 0.5, 0.5],\n",
       "       [0.5, 0.5, 0.5, 0.5],\n",
       "       [0.5, 0.5, 0.5, 0.5],\n",
       "       [0.5, 0.5, 0.5, 0.5],\n",
       "       [0.5, 0.5, 0.5, 0.5]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network[0].weight.data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5, 0.5, 0.5, 0.5])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network[0].weight.data()[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We can also apply different initializers for certain blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "network[0].initialize(mxnet.init.Xavier(),force_reinit=True)\n",
    "network[1].initialize(mxnet.init.Normal(sigma=0.1),force_reinit=True)\n",
    "network[2].initialize(mxnet.init.Constant(1),force_reinit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.29841286,  0.58742774,  0.782645  ,  0.35210955],\n",
       "       [ 0.24438798,  0.44253576,  0.6221672 , -0.66769755]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network[0].weight.data()[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.043648  ,  0.15423739,  0.07354638, -0.01657329,  0.07273798],\n",
       "       [ 0.03766086, -0.00454513,  0.14672141,  0.05573305,  0.08283143],\n",
       "       [ 0.14260544, -0.07045387,  0.14156336, -0.01435713, -0.06850393]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network[1].weight.data()[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1.],\n",
       "       [1., 1., 1.]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network[2].weight.data()[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyInit(mxnet.init.Initializer):\n",
    "    def _init_weight(self,name,data):\n",
    "        print(name,data.shape)\n",
    "        data[:]=np.random.uniform(-10,10,data.shape)\n",
    "        data*=np.abs(data)>=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense7_weight (5, 4)\n",
      "dense8_weight (3, 5)\n",
      "dense9_weight (10, 3)\n"
     ]
    }
   ],
   "source": [
    "network.initialize(init=MyInit(),force_reinit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.      ,  8.39476 , -7.311439],\n",
       "       [ 9.21533 , -5.912525,  0.      ]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network[2].weight.data()[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tied Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True]\n",
      "[ True  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "net = nn.Sequential()\n",
    "# We need to give the shared layer a name so that we can refer to its\n",
    "# parameters\n",
    "shared = nn.Dense(4, activation='relu')\n",
    "net.add(nn.Dense(4, activation='relu'),shared,\n",
    "nn.Dense(4, activation='relu', params=shared.params),\n",
    "nn.Dense(10))\n",
    "net.initialize()\n",
    "X = np.random.uniform(size=(2, 20))\n",
    "net(X)\n",
    "# Check whether the parameters are the same\n",
    "print(net[1].weight.data()[0] == net[2].weight.data()[0])\n",
    "net[1].weight.data()[0, 0] = 100\n",
    "# Make sure that they are actually the same object rather than just having the\n",
    "# same value\n",
    "print(net[1].weight.data()[0] == net[2].weight.data()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><kbd> This example shows that the parameters of the second and third layer are tied. They are not just equal, they are represented by the same exact tensor. Thus, if we change one of the parameters, the other one changes, too. You might wonder, when parameters are tied what happens to the gradients? Since the model parameters contain gradients, the gradients of the second hidden layer and the third hidden layer are added together during backpropagation\n",
    "</kbd></h1>\n",
    "\n",
    " (source: From the book am using: Dive into Deep Learning by Aston Zhang, Zachary C. Lipton, Mu Li, and Alexander J. Smola page 212)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Saving Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For individual tensors, we can directly invoke the load and save functions to read and write them\n",
    "respectively. Both functions require that we supply a name, and save requires as input the variable\n",
    "to be saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.random.rand(5,2)\n",
    "npx.save('data/x-file',x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " reading the data from the stored file back into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.37129477, 0.4562225 ],\n",
       "        [0.6757552 , 0.59618443],\n",
       "        [0.91564703, 0.42880976],\n",
       "        [0.09512343, 0.5551939 ],\n",
       "        [0.48494202, 0.41693395]])]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=npx.load('data/x-file')\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.78078854, 0.40046972],\n",
       "       [0.64849687, 0.6953465 ],\n",
       "       [0.1265121 , 0.09285121],\n",
       "       [0.8600266 , 0.16654207]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=np.random.uniform(size=(4,2))\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Loading and Saving Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Block):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MLP, self).__init__(**kwargs)\n",
    "        self.hidden = nn.Dense(256, activation='relu')\n",
    "        self.output = nn.Dense(10)\n",
    "    def forward(self, x):\n",
    "        return self.output(self.hidden(x))\n",
    "net = MLP()\n",
    "net.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.uniform(size=(2, 20))\n",
    "Y = net(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we store the parameters of the model as a file with the name “mlp.params”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.save_parameters('saved_models/mpl.params')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To recover the model, we instantiate a clone of the original MLP model. Instead of randomly\n",
    "initializing the model parameters, we read the parameters stored in the file directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "clone=MLP()\n",
    "clone.load_parameters('saved_models/mpl.params')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since both instances have the same model parameters, the computational result of the same input\n",
    "X should be the same. Let us verify this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_clone=clone(X)\n",
    "Y_clone==Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_gpu(i=0): #@save\\\n",
    "    \"\"\"Return gpu(i) if exists, otherwise return cpu().\"\"\"\n",
    "    return npx.gpu(i) if npx.num_gpus() >= i + 1 else npx.cpu()\n",
    "def try_all_gpus(): #@save\n",
    "    \"\"\"Return all available GPUs, or [cpu()] if no GPU exists.\"\"\"\n",
    "    devices = [npx.gpu(i) for i in range(npx.num_gpus())]\n",
    "    return devices if devices else [npx.cpu()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(cpu(0), cpu(0), [cpu(0)])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try_gpu(), try_gpu(10), try_all_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, tensors are created on the CPU. We can query the device where the tensor is located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cpu(0)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=np.array([3,2])\n",
    "x.ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

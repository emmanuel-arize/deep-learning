{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "620281c0",
   "metadata": {},
   "source": [
    "# Variational Autoencoders (VAE)\n",
    "\n",
    "VAE is made up of two sub-networks, the encoder and decoder. The encoder instead of compressing the input data to a fixed latent vector in the latent space, turns the input image into two parameters of statistical distributions, the mean $\\mu$ which represent the most likely position of the image in the latent space and the standard deviation $\\sigma$ which represent the size of the circular area around the position where the image could be. A random latent vector $z$ is then sampled from a latent normal distribution $P_{model}(z)$ from the encoder in each forward pass. The decoder then pick the sampled $z$ (a multivariate normal distribution) and tries to reconstructe $z$ as close as possible to the original input data. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd2e588",
   "metadata": {},
   "source": [
    "Let‚Äôs use $x$ as the vector representing the set of all observed variables. We assumed to be sample from an unknown underlying process, whose true (probability) distribution $P^{*}(x)$ is unknown. We chose a model $P(x)$ to approximate the unknow underlying process and the true distribution of the data $P^{*}(x)$ \n",
    "$$x \\sim P(x) \\approx P^{*}(x)$$\n",
    "\n",
    "\n",
    "Approximating the conditional density of the latent variable given observed variable $P(z|x)$ is intractable. So we pick a $Q(z|x)$  to estimate $P(z|x)$  with the intention of making $Q(z|x)$ as close as possible to the true posterior $P(z|x)$. In this case $Q(z|x)$ is taking to be a Gaussian distribution\n",
    "\n",
    "$P(x)$ the marginal likelihood\n",
    "\n",
    "$Q(z|x)=encoder$\n",
    "\n",
    "$P(x|z)=decoder$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61dadf47",
   "metadata": {},
   "source": [
    "\n",
    "**Reparameterizing the Sampling layer**\n",
    "\n",
    "Sampling $z$ directly from $z \\sim \\mathcal{N}(0,1)$ creates a bottleneck since gradients cannot flow back through a random sampling operation we cannot directly backpropagate gradients through the random variable z. In order to allow gradients to flow during backpropagation instead of directly sampling $z$ from the encoder output, we use a **Reparameterization trick** in which $z$ is approximated by\n",
    "\n",
    "\n",
    "$$z=\\mu +\\sigma \\odot \\epsilon  $$ where $$\\epsilon \\sim \\mathcal{N}(0,1)$$\n",
    "\n",
    "Instead of using the variance directly we the **log-var vector**\n",
    "\n",
    "$$log(\\sigma ^2) =2 log(\\sigma)$$\n",
    "$$ \\sigma=exp^{\\frac{log(\\sigma^2)}{2}}$$\n",
    "so $z$ becomes \n",
    "\n",
    "$$z=\\mu +exp^{\\frac{log(\\sigma^2)}{2}} \\odot \\epsilon  $$ \n",
    "\n",
    "Because $\\epsilon$ (random noise) is random process it ensures that points in the neighborhood where you encode the input image decode something similar to the imput image, thus ensuring meanful continuous distribution. Points in the neighborhood will decode to highly similar images "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90129f2f",
   "metadata": {},
   "source": [
    "![](../images/gan1.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ed0c57",
   "metadata": {},
   "source": [
    "# LOSS\n",
    " Using a loss function we want to know the amount of information lost when we go from $x$ to $z$ then to $\\acute{x}$.VAE is trained via two losses, the **rconstruction loss** which measures how effective the decoder has learned to\n",
    "reconstruct $x$ given the latent representation $z$ and **regularization term**\n",
    "\n",
    "Loss= rconstruction loss  +   regularization term\n",
    "\n",
    "$$P(ùë•, ùëß) = P(ùë• |ùëß) P (ùëß) = P (ùëß|ùë•) P(ùë•)$$\n",
    "\n",
    "Applying bayes' Rule\n",
    "\n",
    "$$P(x)=\\frac{P(x|z)P(z)}{P(z|x)}$$\n",
    "\n",
    "where $P(x|z)$ is computed using the decoder, $P(z)$ is the prior  latent vector distribution assumed to be a gaussian.\n",
    "Computing the true posterior $P(z|x)$ is intractable so we train another network called encoder $Q(z|x)$ to approximates the true but intractable posterior $P(z|x)$\n",
    "\n",
    "$$ Q(z|x) \\approx P(z|x)$$\n",
    "$$P(x)=\\frac{P(x|z)P(z)}{P(z|x)}$$\n",
    "\n",
    "Multiplying both  top and bottom by $Q(z|x)$ we get\n",
    "$$ P(x)=log \\ \\frac{P(x|z)P(z)}{P(z|x)} = \\frac{P(x|z)P(z) Q(z|x)}{P(z|x)Q(z|x)}$$\n",
    "\n",
    "$$log \\ P(x)=log \\ \\frac{P(x|z)P(z)}{P(z|x)} = log \\ \\frac{P(x|z)P(z) Q(z|x)}{P(z|x)Q(z|x)}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7be67e",
   "metadata": {},
   "source": [
    "$$log \\ P(x) =log P(x|z) - \\ log \\frac{Q(z|x)}{P(z)} +  \\ log \\frac{Q(z|x)}{P(z|x)} $$\n",
    "**NOTE:**  $ log \\ P(x)=E_{z \\sim Q(z|x)}log \\ P(x)$\n",
    "$$log \\ P(x) =E_{z \\sim Q(z|x)} \\left[ log P(x|z) \\right] - E_{z \\sim Q(z|x)} \\left[ \\ log \\frac{Q(z|x)}{P(z)}\\right] +  E_{z \\sim Q(z|x)} \\left[\\ log \\frac{Q(z|x)}{P(z|x)} \\right]$$\n",
    "\n",
    "\n",
    "$$log \\ P(x) =E_{z \\sim Q(z|x)} \\left[ log P(x|z) \\right] - D_{KL}(Q(z|x)||P(z)+ \\ D_{KL}(Q(z|x)||P(z|x)  $$\n",
    "\n",
    "\n",
    "$E_{z \\sim Q(z|x)} \\left[ log P(x|z) \\right] $ is the data reconstruction error, $D_{KL}(Q(z|x)||P(z)$ is the KL divergence between the encoder network (the latent vector $z$ condition on the input $x$) and the prior and samples nwhich we assumed to be gaussian$z$  .\n",
    "\n",
    "\n",
    "$ D_{KL}(Q(z|x)||P(z|x) $ is the KL divergence between the encoder and posterior of decoder. Because $P(z|x)$ is intractable so we drop \n",
    "\n",
    "$ D_{KL}(Q(z|x)||P(z|x)$ and since $KL \\ge 0$, dropping $ D_{KL}(Q(z|x)||P(z|x) $  gives a lower bound on the data likelihood.\n",
    "\n",
    "$$log \\ P(x) \\ge E_{z \\sim Q(z|x)} \\left[ log P(x|z) \\right] - D_{KL}(Q(z|x)||P(z) $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf775fe6",
   "metadata": {},
   "source": [
    "From [Kullback‚ÄìLeibler divergence](https://en.wikipedia.org/wiki/Kullback‚ÄìLeibler_divergence)\n",
    "A special case, and a common quantity in variational inference, is the relative entropy between a diagonal multivariate normal, and a standard normal distribution (with zero mean and unit variance):\n",
    "\n",
    "$$D_{kL}(N(\\mu_i,\\sigma_i)||N(0,\\mathbb{1})=\\frac{1}{2}\\sum_i^{n}(1+\\sigma^2-\\mu^{2}-In(\\sigma^{2}))$$\n",
    "\n",
    "so in this tutorial \n",
    "\n",
    "**Loss=Binary cross entropy +$\\frac{1}{2}\\sum_i^{n}(1+\\sigma^2-\\mu^{2}-In(\\sigma^{2}))$**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569dd59c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f205e6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "plt.rcParams['image.cmap']='gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88541712",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data = datasets.FashionMNIST( root = '../data',train = True,transform = ToTensor(), download = True)\n",
    "test_data = datasets.FashionMNIST(root = '../data', train = False, transform = ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33059852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data),len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bae2aaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader=DataLoader(train_data,batch_size=100,shuffle=True)\n",
    "test_data_loader=DataLoader(test_data,batch_size=100,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f526b02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image batch dimensions: torch.Size([100, 1, 28, 28])\n",
      "Image label dimensions: torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_data_loader:  \n",
    "    print('Image batch dimensions:', images.shape)\n",
    "    print('Image label dimensions:', labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd6d339e",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20259a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reshape(nn.Module):\n",
    "    def __init__(self,*args):\n",
    "        super().__init__()\n",
    "        self.shape=args\n",
    "    def forward(self, x):\n",
    "        return x.view(self.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85ff75ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self,latent_dim):\n",
    "        super().__init__()\n",
    "        self.latent_dim=latent_dim\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "                nn.Conv2d(1, 32, stride=(1, 1), kernel_size=(3, 3), padding=1),\n",
    "                nn.LeakyReLU(0.01),\n",
    "                nn.Conv2d(32, 64, stride=(2, 2), kernel_size=(3, 3), padding=1),\n",
    "                nn.LeakyReLU(0.01),\n",
    "                nn.Conv2d(64, 72, stride=(2, 2), kernel_size=(3, 3), padding=1),\n",
    "                nn.LeakyReLU(0.01),\n",
    "                nn.Conv2d(72, 64, stride=(1, 1), kernel_size=(3, 3), padding=1),\n",
    "                nn.Flatten(),\n",
    "        ) \n",
    "        \n",
    "        self.z_mean=nn.Linear(3136,self.latent_dim)\n",
    "        self.z_log_var=nn.Linear(3136,self.latent_dim)\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "                torch.nn.Linear(self.latent_dim, 3136),\n",
    "                Reshape(-1, 64, 7, 7),\n",
    "                nn.ConvTranspose2d(64, 64, kernel_size=3,stride=1, padding=1),\n",
    "                nn.LeakyReLU(0.01),\n",
    "                nn.ConvTranspose2d(64, 72, kernel_size=3,stride=2, padding=1),                \n",
    "                nn.LeakyReLU(0.01),\n",
    "                nn.ConvTranspose2d(72, 32, kernel_size=3, stride=2,padding=0),                \n",
    "                nn.LeakyReLU(0.01),\n",
    "                nn.ConvTranspose2d(32, 1, kernel_size=4,stride=1, padding=1), \n",
    "                nn.Sigmoid()\n",
    "                )\n",
    "\n",
    "\n",
    "        \n",
    "    def Reparametrization(self,x):\n",
    "        z_mean=self.z_mean(x)\n",
    "        z_log_var=self.z_log_var(x)\n",
    "        batch=z_mean.shape[0]\n",
    "        dim=z_mean.shape[1]\n",
    "        eps=torch.randn(batch,dim)\n",
    "        z=z_mean+torch.exp(0.5*z_log_var)*eps\n",
    "        return z_mean,z_log_var,z\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        z_mean,z_log_var,z=self.Reparametrization(x)\n",
    "        output = self.decoder(z)\n",
    "        return z_mean,z_log_var,output\n",
    "vae=VAE(latent_dim=latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f066d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "‚îú‚îÄSequential: 1-1                        [-1, 3136]                --\n",
      "|    ‚îî‚îÄConv2d: 2-1                       [-1, 32, 28, 28]          320\n",
      "|    ‚îî‚îÄLeakyReLU: 2-2                    [-1, 32, 28, 28]          --\n",
      "|    ‚îî‚îÄConv2d: 2-3                       [-1, 64, 14, 14]          18,496\n",
      "|    ‚îî‚îÄLeakyReLU: 2-4                    [-1, 64, 14, 14]          --\n",
      "|    ‚îî‚îÄConv2d: 2-5                       [-1, 72, 7, 7]            41,544\n",
      "|    ‚îî‚îÄLeakyReLU: 2-6                    [-1, 72, 7, 7]            --\n",
      "|    ‚îî‚îÄConv2d: 2-7                       [-1, 64, 7, 7]            41,536\n",
      "|    ‚îî‚îÄFlatten: 2-8                      [-1, 3136]                --\n",
      "‚îú‚îÄLinear: 1-2                            [-1, 64]                  200,768\n",
      "‚îú‚îÄLinear: 1-3                            [-1, 64]                  200,768\n",
      "‚îú‚îÄSequential: 1-4                        [-1, 1, 28, 28]           --\n",
      "|    ‚îî‚îÄLinear: 2-9                       [-1, 3136]                203,840\n",
      "|    ‚îî‚îÄReshape: 2-10                     [-1, 64, 7, 7]            --\n",
      "|    ‚îî‚îÄConvTranspose2d: 2-11             [-1, 64, 7, 7]            36,928\n",
      "|    ‚îî‚îÄLeakyReLU: 2-12                   [-1, 64, 7, 7]            --\n",
      "|    ‚îî‚îÄConvTranspose2d: 2-13             [-1, 72, 13, 13]          41,544\n",
      "|    ‚îî‚îÄLeakyReLU: 2-14                   [-1, 72, 13, 13]          --\n",
      "|    ‚îî‚îÄConvTranspose2d: 2-15             [-1, 32, 27, 27]          20,768\n",
      "|    ‚îî‚îÄLeakyReLU: 2-16                   [-1, 32, 27, 27]          --\n",
      "|    ‚îî‚îÄConvTranspose2d: 2-17             [-1, 1, 28, 28]           513\n",
      "|    ‚îî‚îÄSigmoid: 2-18                     [-1, 1, 28, 28]           --\n",
      "==========================================================================================\n",
      "Total params: 807,025\n",
      "Trainable params: 807,025\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 33.24\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.66\n",
      "Params size (MB): 3.08\n",
      "Estimated Total Size (MB): 3.75\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "‚îú‚îÄSequential: 1-1                        [-1, 3136]                --\n",
       "|    ‚îî‚îÄConv2d: 2-1                       [-1, 32, 28, 28]          320\n",
       "|    ‚îî‚îÄLeakyReLU: 2-2                    [-1, 32, 28, 28]          --\n",
       "|    ‚îî‚îÄConv2d: 2-3                       [-1, 64, 14, 14]          18,496\n",
       "|    ‚îî‚îÄLeakyReLU: 2-4                    [-1, 64, 14, 14]          --\n",
       "|    ‚îî‚îÄConv2d: 2-5                       [-1, 72, 7, 7]            41,544\n",
       "|    ‚îî‚îÄLeakyReLU: 2-6                    [-1, 72, 7, 7]            --\n",
       "|    ‚îî‚îÄConv2d: 2-7                       [-1, 64, 7, 7]            41,536\n",
       "|    ‚îî‚îÄFlatten: 2-8                      [-1, 3136]                --\n",
       "‚îú‚îÄLinear: 1-2                            [-1, 64]                  200,768\n",
       "‚îú‚îÄLinear: 1-3                            [-1, 64]                  200,768\n",
       "‚îú‚îÄSequential: 1-4                        [-1, 1, 28, 28]           --\n",
       "|    ‚îî‚îÄLinear: 2-9                       [-1, 3136]                203,840\n",
       "|    ‚îî‚îÄReshape: 2-10                     [-1, 64, 7, 7]            --\n",
       "|    ‚îî‚îÄConvTranspose2d: 2-11             [-1, 64, 7, 7]            36,928\n",
       "|    ‚îî‚îÄLeakyReLU: 2-12                   [-1, 64, 7, 7]            --\n",
       "|    ‚îî‚îÄConvTranspose2d: 2-13             [-1, 72, 13, 13]          41,544\n",
       "|    ‚îî‚îÄLeakyReLU: 2-14                   [-1, 72, 13, 13]          --\n",
       "|    ‚îî‚îÄConvTranspose2d: 2-15             [-1, 32, 27, 27]          20,768\n",
       "|    ‚îî‚îÄLeakyReLU: 2-16                   [-1, 32, 27, 27]          --\n",
       "|    ‚îî‚îÄConvTranspose2d: 2-17             [-1, 1, 28, 28]           513\n",
       "|    ‚îî‚îÄSigmoid: 2-18                     [-1, 1, 28, 28]           --\n",
       "==========================================================================================\n",
       "Total params: 807,025\n",
       "Trainable params: 807,025\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 33.24\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.66\n",
       "Params size (MB): 3.08\n",
       "Estimated Total Size (MB): 3.75\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.randn((1,1,28,28))\n",
    "summary(vae,x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7a0c8a",
   "metadata": {},
   "source": [
    "for name ,params in vae.named_parameters():\n",
    "    print(name, '\\t\\t' ,params.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eb27a76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=torch.optim.Adam(vae.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4429f7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(30):\n",
    "    vae.train()\n",
    "    for x,_ in train_data_loader:\n",
    "        z_mean,z_log_var, output=vae(x)\n",
    "        kl_loss=-0.5*torch.sum(1+z_log_var-z_mean**2-torch.exp(z_log_var))\n",
    "        bce=nn.functional.binary_cross_entropy(output,x.reshape(output.shape))\n",
    "        train_loss=bce+kl_loss.mean()\n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"Epoch %d: train loss %.3f\" % (epoch+1, train_loss.detach().numpy().mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003e3fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.eval()\n",
    "for x_test,_ in test_data_loader:\n",
    "    z_mean_t,z_log_var_t,pred_con=vae(x_test)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bed8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "image_width = 28\n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "orig_imgs = x_test[:n]\n",
    "decoded_imgs = pred_con[:n]\n",
    "\n",
    "for i in range(n):\n",
    "\n",
    "    # display original + noise\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.title(\"original\")\n",
    "    plt.imshow(orig_imgs[i].detach().view((image_width, image_width)) )\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    bx = plt.subplot(2, n, i + n + 1)\n",
    "    plt.title(\"reconstructed\")\n",
    "    plt.imshow(decoded_imgs[i].detach().view((image_width, image_width))   )\n",
    "    plt.gray()\n",
    "    bx.get_xaxis().set_visible(False)\n",
    "    bx.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc3d826",
   "metadata": {},
   "source": [
    "<b>References </b>\n",
    "\n",
    "-  [Evidence lower bound](https://en.wikipedia.org/wiki/Evidence_lower_bound)\n",
    "-  [Kullback‚ÄìLeibler divergence](https://en.wikipedia.org/wiki/Kullback‚ÄìLeibler_divergence)\n",
    "- [ Variational Bayesian methods](https://en.wikipedia.org/wiki/Variational_Bayesian_methods)\n",
    "- [Tutorial on Variational Autoencoders](https://arxiv.org/abs/1606.05908)\n",
    "- [An Introduction to Variational Autoencoders](https://arxiv.org/abs/1906.02691)\n",
    "- [Variational AutoEncoder (keras.io)](https://keras.io/examples/generative/vae/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f797df0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
